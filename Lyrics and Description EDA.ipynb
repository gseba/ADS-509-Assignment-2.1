{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f79baf9",
   "metadata": {},
   "source": [
    "# ADS 509 Assignment 2.1: Tokenization, Normalization, Descriptive Statistics \n",
    "## Ghassan Seba\n",
    "\n",
    "This notebook holds Assignment 2.1 for Module 2 in ADS 509, Applied Text Mining. Work through this notebook, writing code and answering questions where required. \n",
    "\n",
    "In the previous assignment you put together Twitter data and lyrics data on two artists. In this assignment we explore some of the textual features of those data sets. If, for some reason, you did not complete that previous assignment, data to use for this assignment can be found in the assignment materials section of Blackboard. \n",
    "\n",
    "This assignment asks you to write a short function to calculate some descriptive statistics on a piece of text. Then you are asked to find some interesting and unique statistics on your corpora. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d096b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "sw = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b555ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any additional import statements you need here\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Download stopwords & punkt tokenizer resources from nltk Library\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "import string\n",
    "import matplotlib.pyplot as plt \n",
    "from contextlib import redirect_stdout\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "923b5a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Points to the current directory where the Jupyter Notebook is located\n",
    "data_location = \"./\"\n",
    "\n",
    "# Subfolder paths relative to the current directory\n",
    "twitter_folder = \"twitter/\"\n",
    "lyrics_folder = \"lyrics/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06522af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_stats(tokens, num_tokens = 5, verbose=True) :\n",
    "    \"\"\"\n",
    "        Given a list of tokens, print number of tokens, number of unique tokens, \n",
    "        number of characters, lexical diversity (https://en.wikipedia.org/wiki/Lexical_diversity), \n",
    "        and num_tokens most common tokens. Return a list with the number of tokens, number\n",
    "        of unique tokens, lexical diversity, and number of characters. \n",
    "    \n",
    "    \"\"\"\n",
    "    # Calculate the required values\n",
    "    num_tokens = len(tokens)  \n",
    "    num_unique_tokens = len(set(tokens))  # Cast as a set to remove duplicates\n",
    "    lexical_diversity = num_unique_tokens / num_tokens if num_tokens > 0 else 0  # Avoid dividing by zero\n",
    "    num_characters = sum(map(len, tokens))\n",
    "    \n",
    "    if verbose:\n",
    "        # print(*tokens, sep='|')\n",
    "        print(f\"\\nThere are {num_tokens} tokens in the data.\")\n",
    "        print(f\"There are {num_unique_tokens} unique tokens in the data.\")\n",
    "        print(f\"There are {num_characters} characters in the data.\")\n",
    "        print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")\n",
    "        print()  # Add a blank line for spacing\n",
    "    \n",
    "        # print the five most common tokens\n",
    "    return([num_tokens, num_unique_tokens,\n",
    "            lexical_diversity,\n",
    "            num_characters])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59dcf058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 13 tokens in the data.\n",
      "There are 9 unique tokens in the data.\n",
      "There are 55 characters in the data.\n",
      "The lexical diversity is 0.692 in the data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"here is some example text with other example text here in this text\"\"\".split()\n",
    "assert(descriptive_stats(text, verbose=True)[0] == 13)\n",
    "assert(descriptive_stats(text, verbose=False)[1] == 9)\n",
    "assert(abs(descriptive_stats(text, verbose=False)[2] - 0.69) < 0.02)\n",
    "assert(descriptive_stats(text, verbose=False)[3] == 55)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e7e1a2",
   "metadata": {},
   "source": [
    "Q: Why is it beneficial to use assertion statements in your code? \n",
    "\n",
    "***A: Assertion statements are helpful because they allow us to check if our code is working as we expect it to. They catch mistakes early by checking if certain assumptions are true during execution, or they will raise an error, highlighting the problem.*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3bf93e",
   "metadata": {},
   "source": [
    "## Data Input\n",
    "\n",
    "Now read in each of the corpora. For the lyrics data, it may be convenient to store the entire contents of the file to make it easier to inspect the titles individually, as you'll do in the last part of the assignment. In the solution, I stored the lyrics data in a dictionary with two dimensions of keys: artist and song. The value was the file contents. A data frame would work equally well. \n",
    "\n",
    "For the Twitter data, we only need the description field for this assignment. Feel free all the descriptions read it into a data structure. In the solution, I stored the descriptions as a dictionary of lists, with the key being the artist. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9624c4f8-f9e5-4de8-8e6b-00acb2f5282b",
   "metadata": {},
   "source": [
    "### Lyrics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37d70801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the lyrics data\n",
    "lyrics_folder = \"./lyrics\"\n",
    "\n",
    "# Function to read all text files in a folder\n",
    "def read_lyrics(folder):\n",
    "    artist = os.path.basename(folder)  # Extract the folder name for artist name\n",
    "    lyrics_data = []\n",
    "    for filename in os.listdir(folder):\n",
    "        with open(os.path.join(folder, filename), 'r', encoding='utf-8') as file:\n",
    "            lyrics_entry = file.read()\n",
    "            lyrics_data.append({\"artist\": artist, \"lyrics_entry\": lyrics_entry})  # Append artist and lyrics\n",
    "    return lyrics_data\n",
    "\n",
    "# Read lyrics from \"cher\" and \"robyn\" subfolders\n",
    "cher_lyrics = read_lyrics(os.path.join(lyrics_folder, \"cher\"))\n",
    "robyn_lyrics = read_lyrics(os.path.join(lyrics_folder, \"robyn\"))\n",
    "\n",
    "# Combine both lists of\n",
    "all_lyrics = cher_lyrics + robyn_lyrics\n",
    "# all_lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4145d867-78fd-462c-af5a-06e03edc8ec5",
   "metadata": {},
   "source": [
    "### Convert Combined list to a Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8aa1f7fa-5baf-4a6f-bf34-fe287d20cbbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song_title</th>\n",
       "      <th>song_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"88 Degrees\"</td>\n",
       "      <td>Stuck in L.A., ain't got no friends \\nAnd so H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"A Different Kind Of Love Song\"</td>\n",
       "      <td>What if the world was crazy and I was sane\\nWo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"After All\"</td>\n",
       "      <td>Well, here we are again\\nI guess it must be fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"Again\"</td>\n",
       "      <td>Again evening finds me at your door \\nHere to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"Alfie\"</td>\n",
       "      <td>What's it all about, Alfie?\\nIs it just for th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                       song_title  \\\n",
       "0   cher                     \"88 Degrees\"   \n",
       "1   cher  \"A Different Kind Of Love Song\"   \n",
       "2   cher                      \"After All\"   \n",
       "3   cher                          \"Again\"   \n",
       "4   cher                          \"Alfie\"   \n",
       "\n",
       "                                         song_lyrics  \n",
       "0  Stuck in L.A., ain't got no friends \\nAnd so H...  \n",
       "1  What if the world was crazy and I was sane\\nWo...  \n",
       "2  Well, here we are again\\nI guess it must be fa...  \n",
       "3  Again evening finds me at your door \\nHere to ...  \n",
       "4  What's it all about, Alfie?\\nIs it just for th...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to extract artist, song title, and lyrics\n",
    "def parse_lyrics(lyrics_entry, artist):\n",
    "    \n",
    "    # Separate the song title from the lyrics\n",
    "    song_title, song_lyrics = lyrics_entry.split('\\n\\n\\n\\n', 1)\n",
    "    \n",
    "    # Return a dictionary with the parsed data\n",
    "    return {\"artist\": artist, \"song_title\": song_title, \"song_lyrics\": song_lyrics}\n",
    "\n",
    "# Apply the function and create a list of dictionaries\n",
    "parsed_lyrics = [parse_lyrics(entry['lyrics_entry'], entry['artist']) for entry in all_lyrics]\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "lyrics_df = pd.DataFrame(parsed_lyrics)\n",
    "\n",
    "# Display the DataFrame\n",
    "lyrics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7717aa72-7f17-4e1e-a84e-2ce26f4a2447",
   "metadata": {},
   "source": [
    "### Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "debcac5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cher</td>\n",
       "      <td>hsmcnp</td>\n",
       "      <td>Country Girl</td>\n",
       "      <td>35152213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1302</td>\n",
       "      <td>1014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cher</td>\n",
       "      <td>horrormomy</td>\n",
       "      <td>Jeny</td>\n",
       "      <td>742153090850164742</td>\n",
       "      <td>Earth</td>\n",
       "      <td>81</td>\n",
       "      <td>514</td>\n",
       "      <td>ğ™¿ğš›ğš˜ğšğš ğšœğšğš™ğš™ğš˜ğš›ğšğšğš› ğš˜ğš ğš–ğšğšœğšœğš¢ ğš‹ğšğš—ğšœ &amp; ğš•ğšğšğšğš’ğš—ğšğšœ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cher</td>\n",
       "      <td>anju79990584</td>\n",
       "      <td>anju</td>\n",
       "      <td>1496463006451974150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>140</td>\n",
       "      <td>163ãï¼æ„›ã‹ã£ã·ğŸ’œ26æ­³ğŸ’ å·¥ã€‡å¥½ããªå¥³ã®å­ğŸ’“ ãƒ•ã‚©ãƒ­ãƒ¼ã—ã¦ãã‚ŒãŸã‚‰DMã—ã¾ã™ğŸ§¡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cher</td>\n",
       "      <td>gallionjenna</td>\n",
       "      <td>J</td>\n",
       "      <td>3366479914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>752</td>\n",
       "      <td>556</td>\n",
       "      <td>csu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cher</td>\n",
       "      <td>bcscomm</td>\n",
       "      <td>bcscomm</td>\n",
       "      <td>83915043</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>888</td>\n",
       "      <td>2891</td>\n",
       "      <td>Writer @Washinformer @SpelmanCollege alumna #D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist   screen_name          name                   id        location  \\\n",
       "0   Cher        hsmcnp  Country Girl             35152213             NaN   \n",
       "1   Cher    horrormomy          Jeny   742153090850164742           Earth   \n",
       "2   Cher  anju79990584          anju  1496463006451974150             NaN   \n",
       "3   Cher  gallionjenna             J           3366479914             NaN   \n",
       "4   Cher       bcscomm       bcscomm             83915043  Washington, DC   \n",
       "\n",
       "   followers_count  friends_count  \\\n",
       "0             1302           1014   \n",
       "1               81            514   \n",
       "2               13            140   \n",
       "3              752            556   \n",
       "4              888           2891   \n",
       "\n",
       "                                         description  \n",
       "0                                                NaN  \n",
       "1           ğ™¿ğš›ğš˜ğšğš ğšœğšğš™ğš™ğš˜ğš›ğšğšğš› ğš˜ğš ğš–ğšğšœğšœğš¢ ğš‹ğšğš—ğšœ & ğš•ğšğšğšğš’ğš—ğšğšœ  \n",
       "2          163ãï¼æ„›ã‹ã£ã·ğŸ’œ26æ­³ğŸ’ å·¥ã€‡å¥½ããªå¥³ã®å­ğŸ’“ ãƒ•ã‚©ãƒ­ãƒ¼ã—ã¦ãã‚ŒãŸã‚‰DMã—ã¾ã™ğŸ§¡  \n",
       "3                                                csu  \n",
       "4  Writer @Washinformer @SpelmanCollege alumna #D...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data and add 'artist' column\n",
    "def read_followers_data(file_path, artist_name):\n",
    "    df = pd.read_csv(file_path, delimiter='\\t', quotechar='\"', engine='python', on_bad_lines='skip')\n",
    "    df['artist'] = artist_name\n",
    "    # Reorder columns to make 'Artist' the first column\n",
    "    df = df[['artist'] + [col for col in df.columns if col != 'artist']]\n",
    "    return df\n",
    "\n",
    "# File paths\n",
    "cher_file_path = './twitter/cher_followers_data.txt'\n",
    "robyn_file_path = './twitter/robynkonichiwa_followers_data.txt'\n",
    "\n",
    "# Read data\n",
    "cher_data = read_followers_data(cher_file_path, 'Cher')\n",
    "robyn_data = read_followers_data(robyn_file_path, 'Robyn')\n",
    "\n",
    "# Combine DataFrames\n",
    "twitter_combined = pd.concat([cher_data, robyn_data], ignore_index=True)\n",
    "\n",
    "# Show combined data\n",
    "twitter_combined.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a79ea00c-0957-481a-a5b1-450601934cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4269837, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f3b12",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Now clean and tokenize your data. Remove punctuation chacters (available in the `punctuation` object in the `string` library), split on whitespace, fold to lowercase, and remove stopwords. Store your cleaned data, which must be accessible as an interable for `descriptive_stats`, in new objects or in new columns in your data frame. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71c73d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = set(punctuation) # speeds up comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a612c461-3ef5-4b0e-aff8-0f5f8bb54923",
   "metadata": {},
   "source": [
    "### Create Function to Clean and Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eccc2112-bc28-47b7-9b85-00ccc9b14a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to clean and tokenize text\n",
    "def clean_and_tokenize(text):\n",
    "    # Ensure data is not NaN before processing\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenize by splitting on whitespace and lowering case\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # Remove stopwords\n",
    "    cleaned_tokens = [word for word in tokens if word not in stop_words]\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b327033a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song_title</th>\n",
       "      <th>song_lyrics</th>\n",
       "      <th>cleaned_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"88 Degrees\"</td>\n",
       "      <td>Stuck in L.A., ain't got no friends \\nAnd so H...</td>\n",
       "      <td>[stuck, la, aint, got, friends, hollywood, nut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"A Different Kind Of Love Song\"</td>\n",
       "      <td>What if the world was crazy and I was sane\\nWo...</td>\n",
       "      <td>[world, crazy, sane, would, strange, cant, bel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"After All\"</td>\n",
       "      <td>Well, here we are again\\nI guess it must be fa...</td>\n",
       "      <td>[well, guess, must, fate, weve, tried, deep, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"Again\"</td>\n",
       "      <td>Again evening finds me at your door \\nHere to ...</td>\n",
       "      <td>[evening, finds, door, ask, could, try, dont, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"Alfie\"</td>\n",
       "      <td>What's it all about, Alfie?\\nIs it just for th...</td>\n",
       "      <td>[whats, alfie, moment, live, whats, sort, alfi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                       song_title  \\\n",
       "0   cher                     \"88 Degrees\"   \n",
       "1   cher  \"A Different Kind Of Love Song\"   \n",
       "2   cher                      \"After All\"   \n",
       "3   cher                          \"Again\"   \n",
       "4   cher                          \"Alfie\"   \n",
       "\n",
       "                                         song_lyrics  \\\n",
       "0  Stuck in L.A., ain't got no friends \\nAnd so H...   \n",
       "1  What if the world was crazy and I was sane\\nWo...   \n",
       "2  Well, here we are again\\nI guess it must be fa...   \n",
       "3  Again evening finds me at your door \\nHere to ...   \n",
       "4  What's it all about, Alfie?\\nIs it just for th...   \n",
       "\n",
       "                                      cleaned_lyrics  \n",
       "0  [stuck, la, aint, got, friends, hollywood, nut...  \n",
       "1  [world, crazy, sane, would, strange, cant, bel...  \n",
       "2  [well, guess, must, fate, weve, tried, deep, i...  \n",
       "3  [evening, finds, door, ask, could, try, dont, ...  \n",
       "4  [whats, alfie, moment, live, whats, sort, alfi...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create your clean lyrics data here\n",
    "lyrics_df['cleaned_lyrics'] = lyrics_df['song_lyrics'].apply(clean_and_tokenize)\n",
    "\n",
    "# Display cleaned data\n",
    "lyrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0f22e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>description</th>\n",
       "      <th>cleaned_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cher</td>\n",
       "      <td>hsmcnp</td>\n",
       "      <td>Country Girl</td>\n",
       "      <td>35152213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1302</td>\n",
       "      <td>1014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cher</td>\n",
       "      <td>horrormomy</td>\n",
       "      <td>Jeny</td>\n",
       "      <td>742153090850164742</td>\n",
       "      <td>Earth</td>\n",
       "      <td>81</td>\n",
       "      <td>514</td>\n",
       "      <td>ğ™¿ğš›ğš˜ğšğš ğšœğšğš™ğš™ğš˜ğš›ğšğšğš› ğš˜ğš ğš–ğšğšœğšœğš¢ ğš‹ğšğš—ğšœ &amp; ğš•ğšğšğšğš’ğš—ğšğšœ</td>\n",
       "      <td>[ğ™¿ğš›ğš˜ğšğš, ğšœğšğš™ğš™ğš˜ğš›ğšğšğš›, ğš˜ğš, ğš–ğšğšœğšœğš¢, ğš‹ğšğš—ğšœ, ğš•ğšğšğšğš’ğš—ğšğšœ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cher</td>\n",
       "      <td>anju79990584</td>\n",
       "      <td>anju</td>\n",
       "      <td>1496463006451974150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>140</td>\n",
       "      <td>163ãï¼æ„›ã‹ã£ã·ğŸ’œ26æ­³ğŸ’ å·¥ã€‡å¥½ããªå¥³ã®å­ğŸ’“ ãƒ•ã‚©ãƒ­ãƒ¼ã—ã¦ãã‚ŒãŸã‚‰DMã—ã¾ã™ğŸ§¡</td>\n",
       "      <td>[163ãï¼æ„›ã‹ã£ã·ğŸ’œ26æ­³ğŸ’, å·¥ã€‡å¥½ããªå¥³ã®å­ğŸ’“, ãƒ•ã‚©ãƒ­ãƒ¼ã—ã¦ãã‚ŒãŸã‚‰dmã—ã¾ã™ğŸ§¡]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cher</td>\n",
       "      <td>gallionjenna</td>\n",
       "      <td>J</td>\n",
       "      <td>3366479914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>752</td>\n",
       "      <td>556</td>\n",
       "      <td>csu</td>\n",
       "      <td>[csu]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cher</td>\n",
       "      <td>bcscomm</td>\n",
       "      <td>bcscomm</td>\n",
       "      <td>83915043</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>888</td>\n",
       "      <td>2891</td>\n",
       "      <td>Writer @Washinformer @SpelmanCollege alumna #D...</td>\n",
       "      <td>[writer, washinformer, spelmancollege, alumna,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist   screen_name          name                   id        location  \\\n",
       "0   Cher        hsmcnp  Country Girl             35152213             NaN   \n",
       "1   Cher    horrormomy          Jeny   742153090850164742           Earth   \n",
       "2   Cher  anju79990584          anju  1496463006451974150             NaN   \n",
       "3   Cher  gallionjenna             J           3366479914             NaN   \n",
       "4   Cher       bcscomm       bcscomm             83915043  Washington, DC   \n",
       "\n",
       "   followers_count  friends_count  \\\n",
       "0             1302           1014   \n",
       "1               81            514   \n",
       "2               13            140   \n",
       "3              752            556   \n",
       "4              888           2891   \n",
       "\n",
       "                                         description  \\\n",
       "0                                                NaN   \n",
       "1           ğ™¿ğš›ğš˜ğšğš ğšœğšğš™ğš™ğš˜ğš›ğšğšğš› ğš˜ğš ğš–ğšğšœğšœğš¢ ğš‹ğšğš—ğšœ & ğš•ğšğšğšğš’ğš—ğšğšœ   \n",
       "2          163ãï¼æ„›ã‹ã£ã·ğŸ’œ26æ­³ğŸ’ å·¥ã€‡å¥½ããªå¥³ã®å­ğŸ’“ ãƒ•ã‚©ãƒ­ãƒ¼ã—ã¦ãã‚ŒãŸã‚‰DMã—ã¾ã™ğŸ§¡   \n",
       "3                                                csu   \n",
       "4  Writer @Washinformer @SpelmanCollege alumna #D...   \n",
       "\n",
       "                                 cleaned_description  \n",
       "0                                                 []  \n",
       "1      [ğ™¿ğš›ğš˜ğšğš, ğšœğšğš™ğš™ğš˜ğš›ğšğšğš›, ğš˜ğš, ğš–ğšğšœğšœğš¢, ğš‹ğšğš—ğšœ, ğš•ğšğšğšğš’ğš—ğšğšœ]  \n",
       "2      [163ãï¼æ„›ã‹ã£ã·ğŸ’œ26æ­³ğŸ’, å·¥ã€‡å¥½ããªå¥³ã®å­ğŸ’“, ãƒ•ã‚©ãƒ­ãƒ¼ã—ã¦ãã‚ŒãŸã‚‰dmã—ã¾ã™ğŸ§¡]  \n",
       "3                                              [csu]  \n",
       "4  [writer, washinformer, spelmancollege, alumna,...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create your clean twitter data here\n",
    "twitter_combined['cleaned_description'] = twitter_combined['description'].apply(clean_and_tokenize)\n",
    "\n",
    "# Display cleaned data\n",
    "twitter_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dd0179",
   "metadata": {},
   "source": [
    "## Basic Descriptive Statistics\n",
    "\n",
    "Call your `descriptive_stats` function on both your lyrics data and your twitter data and for both artists (four total calls). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0bbedd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 180 tokens in the data.\n",
      "There are 82 unique tokens in the data.\n",
      "There are 822 characters in the data.\n",
      "The lexical diversity is 0.456 in the data.\n",
      "\n",
      "\n",
      "There are 133 tokens in the data.\n",
      "There are 41 unique tokens in the data.\n",
      "There are 670 characters in the data.\n",
      "The lexical diversity is 0.308 in the data.\n",
      "\n",
      "\n",
      "There are 120 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 603 characters in the data.\n",
      "The lexical diversity is 0.492 in the data.\n",
      "\n",
      "\n",
      "There are 34 tokens in the data.\n",
      "There are 28 unique tokens in the data.\n",
      "There are 143 characters in the data.\n",
      "The lexical diversity is 0.824 in the data.\n",
      "\n",
      "\n",
      "There are 66 tokens in the data.\n",
      "There are 46 unique tokens in the data.\n",
      "There are 334 characters in the data.\n",
      "The lexical diversity is 0.697 in the data.\n",
      "\n",
      "\n",
      "There are 109 tokens in the data.\n",
      "There are 73 unique tokens in the data.\n",
      "There are 486 characters in the data.\n",
      "The lexical diversity is 0.670 in the data.\n",
      "\n",
      "\n",
      "There are 94 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 461 characters in the data.\n",
      "The lexical diversity is 0.574 in the data.\n",
      "\n",
      "\n",
      "There are 81 tokens in the data.\n",
      "There are 48 unique tokens in the data.\n",
      "There are 452 characters in the data.\n",
      "The lexical diversity is 0.593 in the data.\n",
      "\n",
      "\n",
      "There are 141 tokens in the data.\n",
      "There are 44 unique tokens in the data.\n",
      "There are 656 characters in the data.\n",
      "The lexical diversity is 0.312 in the data.\n",
      "\n",
      "\n",
      "There are 67 tokens in the data.\n",
      "There are 29 unique tokens in the data.\n",
      "There are 237 characters in the data.\n",
      "The lexical diversity is 0.433 in the data.\n",
      "\n",
      "\n",
      "There are 100 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 477 characters in the data.\n",
      "The lexical diversity is 0.580 in the data.\n",
      "\n",
      "\n",
      "There are 132 tokens in the data.\n",
      "There are 74 unique tokens in the data.\n",
      "There are 621 characters in the data.\n",
      "The lexical diversity is 0.561 in the data.\n",
      "\n",
      "\n",
      "There are 108 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 479 characters in the data.\n",
      "The lexical diversity is 0.500 in the data.\n",
      "\n",
      "\n",
      "There are 70 tokens in the data.\n",
      "There are 33 unique tokens in the data.\n",
      "There are 372 characters in the data.\n",
      "The lexical diversity is 0.471 in the data.\n",
      "\n",
      "\n",
      "There are 119 tokens in the data.\n",
      "There are 91 unique tokens in the data.\n",
      "There are 648 characters in the data.\n",
      "The lexical diversity is 0.765 in the data.\n",
      "\n",
      "\n",
      "There are 108 tokens in the data.\n",
      "There are 55 unique tokens in the data.\n",
      "There are 488 characters in the data.\n",
      "The lexical diversity is 0.509 in the data.\n",
      "\n",
      "\n",
      "There are 174 tokens in the data.\n",
      "There are 71 unique tokens in the data.\n",
      "There are 744 characters in the data.\n",
      "The lexical diversity is 0.408 in the data.\n",
      "\n",
      "\n",
      "There are 96 tokens in the data.\n",
      "There are 53 unique tokens in the data.\n",
      "There are 429 characters in the data.\n",
      "The lexical diversity is 0.552 in the data.\n",
      "\n",
      "\n",
      "There are 91 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 478 characters in the data.\n",
      "The lexical diversity is 0.593 in the data.\n",
      "\n",
      "\n",
      "There are 177 tokens in the data.\n",
      "There are 53 unique tokens in the data.\n",
      "There are 878 characters in the data.\n",
      "The lexical diversity is 0.299 in the data.\n",
      "\n",
      "\n",
      "There are 160 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 650 characters in the data.\n",
      "The lexical diversity is 0.356 in the data.\n",
      "\n",
      "\n",
      "There are 94 tokens in the data.\n",
      "There are 47 unique tokens in the data.\n",
      "There are 439 characters in the data.\n",
      "The lexical diversity is 0.500 in the data.\n",
      "\n",
      "\n",
      "There are 109 tokens in the data.\n",
      "There are 44 unique tokens in the data.\n",
      "There are 508 characters in the data.\n",
      "The lexical diversity is 0.404 in the data.\n",
      "\n",
      "\n",
      "There are 82 tokens in the data.\n",
      "There are 55 unique tokens in the data.\n",
      "There are 429 characters in the data.\n",
      "The lexical diversity is 0.671 in the data.\n",
      "\n",
      "\n",
      "There are 153 tokens in the data.\n",
      "There are 53 unique tokens in the data.\n",
      "There are 771 characters in the data.\n",
      "The lexical diversity is 0.346 in the data.\n",
      "\n",
      "\n",
      "There are 183 tokens in the data.\n",
      "There are 106 unique tokens in the data.\n",
      "There are 871 characters in the data.\n",
      "The lexical diversity is 0.579 in the data.\n",
      "\n",
      "\n",
      "There are 78 tokens in the data.\n",
      "There are 52 unique tokens in the data.\n",
      "There are 395 characters in the data.\n",
      "The lexical diversity is 0.667 in the data.\n",
      "\n",
      "\n",
      "There are 122 tokens in the data.\n",
      "There are 33 unique tokens in the data.\n",
      "There are 411 characters in the data.\n",
      "The lexical diversity is 0.270 in the data.\n",
      "\n",
      "\n",
      "There are 115 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 492 characters in the data.\n",
      "The lexical diversity is 0.548 in the data.\n",
      "\n",
      "\n",
      "There are 44 tokens in the data.\n",
      "There are 28 unique tokens in the data.\n",
      "There are 192 characters in the data.\n",
      "The lexical diversity is 0.636 in the data.\n",
      "\n",
      "\n",
      "There are 144 tokens in the data.\n",
      "There are 73 unique tokens in the data.\n",
      "There are 747 characters in the data.\n",
      "The lexical diversity is 0.507 in the data.\n",
      "\n",
      "\n",
      "There are 78 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 343 characters in the data.\n",
      "The lexical diversity is 0.692 in the data.\n",
      "\n",
      "\n",
      "There are 124 tokens in the data.\n",
      "There are 46 unique tokens in the data.\n",
      "There are 568 characters in the data.\n",
      "The lexical diversity is 0.371 in the data.\n",
      "\n",
      "\n",
      "There are 97 tokens in the data.\n",
      "There are 66 unique tokens in the data.\n",
      "There are 444 characters in the data.\n",
      "The lexical diversity is 0.680 in the data.\n",
      "\n",
      "\n",
      "There are 135 tokens in the data.\n",
      "There are 67 unique tokens in the data.\n",
      "There are 678 characters in the data.\n",
      "The lexical diversity is 0.496 in the data.\n",
      "\n",
      "\n",
      "There are 180 tokens in the data.\n",
      "There are 83 unique tokens in the data.\n",
      "There are 935 characters in the data.\n",
      "The lexical diversity is 0.461 in the data.\n",
      "\n",
      "\n",
      "There are 73 tokens in the data.\n",
      "There are 49 unique tokens in the data.\n",
      "There are 299 characters in the data.\n",
      "The lexical diversity is 0.671 in the data.\n",
      "\n",
      "\n",
      "There are 20 tokens in the data.\n",
      "There are 8 unique tokens in the data.\n",
      "There are 136 characters in the data.\n",
      "The lexical diversity is 0.400 in the data.\n",
      "\n",
      "\n",
      "There are 78 tokens in the data.\n",
      "There are 48 unique tokens in the data.\n",
      "There are 334 characters in the data.\n",
      "The lexical diversity is 0.615 in the data.\n",
      "\n",
      "\n",
      "There are 123 tokens in the data.\n",
      "There are 88 unique tokens in the data.\n",
      "There are 567 characters in the data.\n",
      "The lexical diversity is 0.715 in the data.\n",
      "\n",
      "\n",
      "There are 143 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 709 characters in the data.\n",
      "The lexical diversity is 0.441 in the data.\n",
      "\n",
      "\n",
      "There are 90 tokens in the data.\n",
      "There are 35 unique tokens in the data.\n",
      "There are 419 characters in the data.\n",
      "The lexical diversity is 0.389 in the data.\n",
      "\n",
      "\n",
      "There are 60 tokens in the data.\n",
      "There are 23 unique tokens in the data.\n",
      "There are 265 characters in the data.\n",
      "The lexical diversity is 0.383 in the data.\n",
      "\n",
      "\n",
      "There are 114 tokens in the data.\n",
      "There are 56 unique tokens in the data.\n",
      "There are 577 characters in the data.\n",
      "The lexical diversity is 0.491 in the data.\n",
      "\n",
      "\n",
      "There are 92 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 483 characters in the data.\n",
      "The lexical diversity is 0.630 in the data.\n",
      "\n",
      "\n",
      "There are 81 tokens in the data.\n",
      "There are 53 unique tokens in the data.\n",
      "There are 350 characters in the data.\n",
      "The lexical diversity is 0.654 in the data.\n",
      "\n",
      "\n",
      "There are 129 tokens in the data.\n",
      "There are 101 unique tokens in the data.\n",
      "There are 647 characters in the data.\n",
      "The lexical diversity is 0.783 in the data.\n",
      "\n",
      "\n",
      "There are 92 tokens in the data.\n",
      "There are 46 unique tokens in the data.\n",
      "There are 452 characters in the data.\n",
      "The lexical diversity is 0.500 in the data.\n",
      "\n",
      "\n",
      "There are 197 tokens in the data.\n",
      "There are 118 unique tokens in the data.\n",
      "There are 952 characters in the data.\n",
      "The lexical diversity is 0.599 in the data.\n",
      "\n",
      "\n",
      "There are 107 tokens in the data.\n",
      "There are 88 unique tokens in the data.\n",
      "There are 516 characters in the data.\n",
      "The lexical diversity is 0.822 in the data.\n",
      "\n",
      "\n",
      "There are 143 tokens in the data.\n",
      "There are 83 unique tokens in the data.\n",
      "There are 735 characters in the data.\n",
      "The lexical diversity is 0.580 in the data.\n",
      "\n",
      "\n",
      "There are 204 tokens in the data.\n",
      "There are 72 unique tokens in the data.\n",
      "There are 1000 characters in the data.\n",
      "The lexical diversity is 0.353 in the data.\n",
      "\n",
      "\n",
      "There are 72 tokens in the data.\n",
      "There are 28 unique tokens in the data.\n",
      "There are 386 characters in the data.\n",
      "The lexical diversity is 0.389 in the data.\n",
      "\n",
      "\n",
      "There are 98 tokens in the data.\n",
      "There are 81 unique tokens in the data.\n",
      "There are 541 characters in the data.\n",
      "The lexical diversity is 0.827 in the data.\n",
      "\n",
      "\n",
      "There are 122 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 545 characters in the data.\n",
      "The lexical diversity is 0.508 in the data.\n",
      "\n",
      "\n",
      "There are 131 tokens in the data.\n",
      "There are 81 unique tokens in the data.\n",
      "There are 608 characters in the data.\n",
      "The lexical diversity is 0.618 in the data.\n",
      "\n",
      "\n",
      "There are 118 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 521 characters in the data.\n",
      "The lexical diversity is 0.483 in the data.\n",
      "\n",
      "\n",
      "There are 102 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 465 characters in the data.\n",
      "The lexical diversity is 0.412 in the data.\n",
      "\n",
      "\n",
      "There are 150 tokens in the data.\n",
      "There are 60 unique tokens in the data.\n",
      "There are 676 characters in the data.\n",
      "The lexical diversity is 0.400 in the data.\n",
      "\n",
      "\n",
      "There are 113 tokens in the data.\n",
      "There are 67 unique tokens in the data.\n",
      "There are 483 characters in the data.\n",
      "The lexical diversity is 0.593 in the data.\n",
      "\n",
      "\n",
      "There are 78 tokens in the data.\n",
      "There are 45 unique tokens in the data.\n",
      "There are 389 characters in the data.\n",
      "The lexical diversity is 0.577 in the data.\n",
      "\n",
      "\n",
      "There are 120 tokens in the data.\n",
      "There are 73 unique tokens in the data.\n",
      "There are 579 characters in the data.\n",
      "The lexical diversity is 0.608 in the data.\n",
      "\n",
      "\n",
      "There are 91 tokens in the data.\n",
      "There are 41 unique tokens in the data.\n",
      "There are 374 characters in the data.\n",
      "The lexical diversity is 0.451 in the data.\n",
      "\n",
      "\n",
      "There are 112 tokens in the data.\n",
      "There are 53 unique tokens in the data.\n",
      "There are 510 characters in the data.\n",
      "The lexical diversity is 0.473 in the data.\n",
      "\n",
      "\n",
      "There are 101 tokens in the data.\n",
      "There are 49 unique tokens in the data.\n",
      "There are 527 characters in the data.\n",
      "The lexical diversity is 0.485 in the data.\n",
      "\n",
      "\n",
      "There are 55 tokens in the data.\n",
      "There are 23 unique tokens in the data.\n",
      "There are 293 characters in the data.\n",
      "The lexical diversity is 0.418 in the data.\n",
      "\n",
      "\n",
      "There are 104 tokens in the data.\n",
      "There are 73 unique tokens in the data.\n",
      "There are 589 characters in the data.\n",
      "The lexical diversity is 0.702 in the data.\n",
      "\n",
      "\n",
      "There are 142 tokens in the data.\n",
      "There are 51 unique tokens in the data.\n",
      "There are 690 characters in the data.\n",
      "The lexical diversity is 0.359 in the data.\n",
      "\n",
      "\n",
      "There are 133 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 626 characters in the data.\n",
      "The lexical diversity is 0.466 in the data.\n",
      "\n",
      "\n",
      "There are 165 tokens in the data.\n",
      "There are 64 unique tokens in the data.\n",
      "There are 848 characters in the data.\n",
      "The lexical diversity is 0.388 in the data.\n",
      "\n",
      "\n",
      "There are 142 tokens in the data.\n",
      "There are 82 unique tokens in the data.\n",
      "There are 806 characters in the data.\n",
      "The lexical diversity is 0.577 in the data.\n",
      "\n",
      "\n",
      "There are 142 tokens in the data.\n",
      "There are 83 unique tokens in the data.\n",
      "There are 805 characters in the data.\n",
      "The lexical diversity is 0.585 in the data.\n",
      "\n",
      "\n",
      "There are 155 tokens in the data.\n",
      "There are 82 unique tokens in the data.\n",
      "There are 697 characters in the data.\n",
      "The lexical diversity is 0.529 in the data.\n",
      "\n",
      "\n",
      "There are 146 tokens in the data.\n",
      "There are 80 unique tokens in the data.\n",
      "There are 714 characters in the data.\n",
      "The lexical diversity is 0.548 in the data.\n",
      "\n",
      "\n",
      "There are 111 tokens in the data.\n",
      "There are 82 unique tokens in the data.\n",
      "There are 500 characters in the data.\n",
      "The lexical diversity is 0.739 in the data.\n",
      "\n",
      "\n",
      "There are 123 tokens in the data.\n",
      "There are 73 unique tokens in the data.\n",
      "There are 667 characters in the data.\n",
      "The lexical diversity is 0.593 in the data.\n",
      "\n",
      "\n",
      "There are 117 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 633 characters in the data.\n",
      "The lexical diversity is 0.538 in the data.\n",
      "\n",
      "\n",
      "There are 79 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 399 characters in the data.\n",
      "The lexical diversity is 0.734 in the data.\n",
      "\n",
      "\n",
      "There are 121 tokens in the data.\n",
      "There are 61 unique tokens in the data.\n",
      "There are 586 characters in the data.\n",
      "The lexical diversity is 0.504 in the data.\n",
      "\n",
      "\n",
      "There are 151 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 707 characters in the data.\n",
      "The lexical diversity is 0.391 in the data.\n",
      "\n",
      "\n",
      "There are 128 tokens in the data.\n",
      "There are 35 unique tokens in the data.\n",
      "There are 488 characters in the data.\n",
      "The lexical diversity is 0.273 in the data.\n",
      "\n",
      "\n",
      "There are 143 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 548 characters in the data.\n",
      "The lexical diversity is 0.294 in the data.\n",
      "\n",
      "\n",
      "There are 111 tokens in the data.\n",
      "There are 73 unique tokens in the data.\n",
      "There are 488 characters in the data.\n",
      "The lexical diversity is 0.658 in the data.\n",
      "\n",
      "\n",
      "There are 94 tokens in the data.\n",
      "There are 37 unique tokens in the data.\n",
      "There are 371 characters in the data.\n",
      "The lexical diversity is 0.394 in the data.\n",
      "\n",
      "\n",
      "There are 107 tokens in the data.\n",
      "There are 74 unique tokens in the data.\n",
      "There are 555 characters in the data.\n",
      "The lexical diversity is 0.692 in the data.\n",
      "\n",
      "\n",
      "There are 71 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 382 characters in the data.\n",
      "The lexical diversity is 0.803 in the data.\n",
      "\n",
      "\n",
      "There are 89 tokens in the data.\n",
      "There are 48 unique tokens in the data.\n",
      "There are 434 characters in the data.\n",
      "The lexical diversity is 0.539 in the data.\n",
      "\n",
      "\n",
      "There are 122 tokens in the data.\n",
      "There are 65 unique tokens in the data.\n",
      "There are 557 characters in the data.\n",
      "The lexical diversity is 0.533 in the data.\n",
      "\n",
      "\n",
      "There are 135 tokens in the data.\n",
      "There are 73 unique tokens in the data.\n",
      "There are 653 characters in the data.\n",
      "The lexical diversity is 0.541 in the data.\n",
      "\n",
      "\n",
      "There are 66 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 319 characters in the data.\n",
      "The lexical diversity is 0.636 in the data.\n",
      "\n",
      "\n",
      "There are 151 tokens in the data.\n",
      "There are 93 unique tokens in the data.\n",
      "There are 764 characters in the data.\n",
      "The lexical diversity is 0.616 in the data.\n",
      "\n",
      "\n",
      "There are 107 tokens in the data.\n",
      "There are 71 unique tokens in the data.\n",
      "There are 516 characters in the data.\n",
      "The lexical diversity is 0.664 in the data.\n",
      "\n",
      "\n",
      "There are 237 tokens in the data.\n",
      "There are 52 unique tokens in the data.\n",
      "There are 1016 characters in the data.\n",
      "The lexical diversity is 0.219 in the data.\n",
      "\n",
      "\n",
      "There are 94 tokens in the data.\n",
      "There are 78 unique tokens in the data.\n",
      "There are 474 characters in the data.\n",
      "The lexical diversity is 0.830 in the data.\n",
      "\n",
      "\n",
      "There are 108 tokens in the data.\n",
      "There are 33 unique tokens in the data.\n",
      "There are 427 characters in the data.\n",
      "The lexical diversity is 0.306 in the data.\n",
      "\n",
      "\n",
      "There are 148 tokens in the data.\n",
      "There are 68 unique tokens in the data.\n",
      "There are 697 characters in the data.\n",
      "The lexical diversity is 0.459 in the data.\n",
      "\n",
      "\n",
      "There are 175 tokens in the data.\n",
      "There are 66 unique tokens in the data.\n",
      "There are 826 characters in the data.\n",
      "The lexical diversity is 0.377 in the data.\n",
      "\n",
      "\n",
      "There are 104 tokens in the data.\n",
      "There are 64 unique tokens in the data.\n",
      "There are 603 characters in the data.\n",
      "The lexical diversity is 0.615 in the data.\n",
      "\n",
      "\n",
      "There are 72 tokens in the data.\n",
      "There are 47 unique tokens in the data.\n",
      "There are 321 characters in the data.\n",
      "The lexical diversity is 0.653 in the data.\n",
      "\n",
      "\n",
      "There are 85 tokens in the data.\n",
      "There are 44 unique tokens in the data.\n",
      "There are 406 characters in the data.\n",
      "The lexical diversity is 0.518 in the data.\n",
      "\n",
      "\n",
      "There are 86 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 386 characters in the data.\n",
      "The lexical diversity is 0.465 in the data.\n",
      "\n",
      "\n",
      "There are 128 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 636 characters in the data.\n",
      "The lexical diversity is 0.445 in the data.\n",
      "\n",
      "\n",
      "There are 149 tokens in the data.\n",
      "There are 60 unique tokens in the data.\n",
      "There are 767 characters in the data.\n",
      "The lexical diversity is 0.403 in the data.\n",
      "\n",
      "\n",
      "There are 83 tokens in the data.\n",
      "There are 46 unique tokens in the data.\n",
      "There are 398 characters in the data.\n",
      "The lexical diversity is 0.554 in the data.\n",
      "\n",
      "\n",
      "There are 88 tokens in the data.\n",
      "There are 45 unique tokens in the data.\n",
      "There are 413 characters in the data.\n",
      "The lexical diversity is 0.511 in the data.\n",
      "\n",
      "\n",
      "There are 201 tokens in the data.\n",
      "There are 65 unique tokens in the data.\n",
      "There are 871 characters in the data.\n",
      "The lexical diversity is 0.323 in the data.\n",
      "\n",
      "\n",
      "There are 74 tokens in the data.\n",
      "There are 48 unique tokens in the data.\n",
      "There are 355 characters in the data.\n",
      "The lexical diversity is 0.649 in the data.\n",
      "\n",
      "\n",
      "There are 132 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 666 characters in the data.\n",
      "The lexical diversity is 0.432 in the data.\n",
      "\n",
      "\n",
      "There are 163 tokens in the data.\n",
      "There are 48 unique tokens in the data.\n",
      "There are 685 characters in the data.\n",
      "The lexical diversity is 0.294 in the data.\n",
      "\n",
      "\n",
      "There are 55 tokens in the data.\n",
      "There are 28 unique tokens in the data.\n",
      "There are 225 characters in the data.\n",
      "The lexical diversity is 0.509 in the data.\n",
      "\n",
      "\n",
      "There are 70 tokens in the data.\n",
      "There are 41 unique tokens in the data.\n",
      "There are 338 characters in the data.\n",
      "The lexical diversity is 0.586 in the data.\n",
      "\n",
      "\n",
      "There are 113 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 460 characters in the data.\n",
      "The lexical diversity is 0.522 in the data.\n",
      "\n",
      "\n",
      "There are 56 tokens in the data.\n",
      "There are 33 unique tokens in the data.\n",
      "There are 253 characters in the data.\n",
      "The lexical diversity is 0.589 in the data.\n",
      "\n",
      "\n",
      "There are 133 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 667 characters in the data.\n",
      "The lexical diversity is 0.466 in the data.\n",
      "\n",
      "\n",
      "There are 42 tokens in the data.\n",
      "There are 18 unique tokens in the data.\n",
      "There are 156 characters in the data.\n",
      "The lexical diversity is 0.429 in the data.\n",
      "\n",
      "\n",
      "There are 106 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 522 characters in the data.\n",
      "The lexical diversity is 0.557 in the data.\n",
      "\n",
      "\n",
      "There are 109 tokens in the data.\n",
      "There are 67 unique tokens in the data.\n",
      "There are 497 characters in the data.\n",
      "The lexical diversity is 0.615 in the data.\n",
      "\n",
      "\n",
      "There are 47 tokens in the data.\n",
      "There are 36 unique tokens in the data.\n",
      "There are 228 characters in the data.\n",
      "The lexical diversity is 0.766 in the data.\n",
      "\n",
      "\n",
      "There are 119 tokens in the data.\n",
      "There are 44 unique tokens in the data.\n",
      "There are 638 characters in the data.\n",
      "The lexical diversity is 0.370 in the data.\n",
      "\n",
      "\n",
      "There are 70 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 378 characters in the data.\n",
      "The lexical diversity is 0.886 in the data.\n",
      "\n",
      "\n",
      "There are 76 tokens in the data.\n",
      "There are 56 unique tokens in the data.\n",
      "There are 392 characters in the data.\n",
      "The lexical diversity is 0.737 in the data.\n",
      "\n",
      "\n",
      "There are 147 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 711 characters in the data.\n",
      "The lexical diversity is 0.429 in the data.\n",
      "\n",
      "\n",
      "There are 83 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 396 characters in the data.\n",
      "The lexical diversity is 0.759 in the data.\n",
      "\n",
      "\n",
      "There are 68 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 342 characters in the data.\n",
      "The lexical diversity is 0.618 in the data.\n",
      "\n",
      "\n",
      "There are 69 tokens in the data.\n",
      "There are 60 unique tokens in the data.\n",
      "There are 320 characters in the data.\n",
      "The lexical diversity is 0.870 in the data.\n",
      "\n",
      "\n",
      "There are 56 tokens in the data.\n",
      "There are 31 unique tokens in the data.\n",
      "There are 250 characters in the data.\n",
      "The lexical diversity is 0.554 in the data.\n",
      "\n",
      "\n",
      "There are 68 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 310 characters in the data.\n",
      "The lexical diversity is 0.794 in the data.\n",
      "\n",
      "\n",
      "There are 85 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 414 characters in the data.\n",
      "The lexical diversity is 0.494 in the data.\n",
      "\n",
      "\n",
      "There are 135 tokens in the data.\n",
      "There are 70 unique tokens in the data.\n",
      "There are 621 characters in the data.\n",
      "The lexical diversity is 0.519 in the data.\n",
      "\n",
      "\n",
      "There are 98 tokens in the data.\n",
      "There are 44 unique tokens in the data.\n",
      "There are 465 characters in the data.\n",
      "The lexical diversity is 0.449 in the data.\n",
      "\n",
      "\n",
      "There are 56 tokens in the data.\n",
      "There are 32 unique tokens in the data.\n",
      "There are 271 characters in the data.\n",
      "The lexical diversity is 0.571 in the data.\n",
      "\n",
      "\n",
      "There are 82 tokens in the data.\n",
      "There are 29 unique tokens in the data.\n",
      "There are 358 characters in the data.\n",
      "The lexical diversity is 0.354 in the data.\n",
      "\n",
      "\n",
      "There are 200 tokens in the data.\n",
      "There are 77 unique tokens in the data.\n",
      "There are 883 characters in the data.\n",
      "The lexical diversity is 0.385 in the data.\n",
      "\n",
      "\n",
      "There are 160 tokens in the data.\n",
      "There are 68 unique tokens in the data.\n",
      "There are 750 characters in the data.\n",
      "The lexical diversity is 0.425 in the data.\n",
      "\n",
      "\n",
      "There are 101 tokens in the data.\n",
      "There are 73 unique tokens in the data.\n",
      "There are 497 characters in the data.\n",
      "The lexical diversity is 0.723 in the data.\n",
      "\n",
      "\n",
      "There are 65 tokens in the data.\n",
      "There are 36 unique tokens in the data.\n",
      "There are 309 characters in the data.\n",
      "The lexical diversity is 0.554 in the data.\n",
      "\n",
      "\n",
      "There are 53 tokens in the data.\n",
      "There are 24 unique tokens in the data.\n",
      "There are 276 characters in the data.\n",
      "The lexical diversity is 0.453 in the data.\n",
      "\n",
      "\n",
      "There are 94 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 430 characters in the data.\n",
      "The lexical diversity is 0.617 in the data.\n",
      "\n",
      "\n",
      "There are 122 tokens in the data.\n",
      "There are 69 unique tokens in the data.\n",
      "There are 543 characters in the data.\n",
      "The lexical diversity is 0.566 in the data.\n",
      "\n",
      "\n",
      "There are 124 tokens in the data.\n",
      "There are 66 unique tokens in the data.\n",
      "There are 581 characters in the data.\n",
      "The lexical diversity is 0.532 in the data.\n",
      "\n",
      "\n",
      "There are 91 tokens in the data.\n",
      "There are 45 unique tokens in the data.\n",
      "There are 448 characters in the data.\n",
      "The lexical diversity is 0.495 in the data.\n",
      "\n",
      "\n",
      "There are 217 tokens in the data.\n",
      "There are 106 unique tokens in the data.\n",
      "There are 951 characters in the data.\n",
      "The lexical diversity is 0.488 in the data.\n",
      "\n",
      "\n",
      "There are 102 tokens in the data.\n",
      "There are 64 unique tokens in the data.\n",
      "There are 465 characters in the data.\n",
      "The lexical diversity is 0.627 in the data.\n",
      "\n",
      "\n",
      "There are 75 tokens in the data.\n",
      "There are 41 unique tokens in the data.\n",
      "There are 382 characters in the data.\n",
      "The lexical diversity is 0.547 in the data.\n",
      "\n",
      "\n",
      "There are 167 tokens in the data.\n",
      "There are 80 unique tokens in the data.\n",
      "There are 803 characters in the data.\n",
      "The lexical diversity is 0.479 in the data.\n",
      "\n",
      "\n",
      "There are 125 tokens in the data.\n",
      "There are 43 unique tokens in the data.\n",
      "There are 643 characters in the data.\n",
      "The lexical diversity is 0.344 in the data.\n",
      "\n",
      "\n",
      "There are 142 tokens in the data.\n",
      "There are 65 unique tokens in the data.\n",
      "There are 685 characters in the data.\n",
      "The lexical diversity is 0.458 in the data.\n",
      "\n",
      "\n",
      "There are 119 tokens in the data.\n",
      "There are 52 unique tokens in the data.\n",
      "There are 498 characters in the data.\n",
      "The lexical diversity is 0.437 in the data.\n",
      "\n",
      "\n",
      "There are 68 tokens in the data.\n",
      "There are 22 unique tokens in the data.\n",
      "There are 249 characters in the data.\n",
      "The lexical diversity is 0.324 in the data.\n",
      "\n",
      "\n",
      "There are 143 tokens in the data.\n",
      "There are 84 unique tokens in the data.\n",
      "There are 690 characters in the data.\n",
      "The lexical diversity is 0.587 in the data.\n",
      "\n",
      "\n",
      "There are 118 tokens in the data.\n",
      "There are 69 unique tokens in the data.\n",
      "There are 523 characters in the data.\n",
      "The lexical diversity is 0.585 in the data.\n",
      "\n",
      "\n",
      "There are 147 tokens in the data.\n",
      "There are 107 unique tokens in the data.\n",
      "There are 778 characters in the data.\n",
      "The lexical diversity is 0.728 in the data.\n",
      "\n",
      "\n",
      "There are 49 tokens in the data.\n",
      "There are 38 unique tokens in the data.\n",
      "There are 257 characters in the data.\n",
      "The lexical diversity is 0.776 in the data.\n",
      "\n",
      "\n",
      "There are 127 tokens in the data.\n",
      "There are 56 unique tokens in the data.\n",
      "There are 617 characters in the data.\n",
      "The lexical diversity is 0.441 in the data.\n",
      "\n",
      "\n",
      "There are 45 tokens in the data.\n",
      "There are 21 unique tokens in the data.\n",
      "There are 196 characters in the data.\n",
      "The lexical diversity is 0.467 in the data.\n",
      "\n",
      "\n",
      "There are 152 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 809 characters in the data.\n",
      "The lexical diversity is 0.375 in the data.\n",
      "\n",
      "\n",
      "There are 109 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 524 characters in the data.\n",
      "The lexical diversity is 0.541 in the data.\n",
      "\n",
      "\n",
      "There are 108 tokens in the data.\n",
      "There are 51 unique tokens in the data.\n",
      "There are 491 characters in the data.\n",
      "The lexical diversity is 0.472 in the data.\n",
      "\n",
      "\n",
      "There are 87 tokens in the data.\n",
      "There are 50 unique tokens in the data.\n",
      "There are 399 characters in the data.\n",
      "The lexical diversity is 0.575 in the data.\n",
      "\n",
      "\n",
      "There are 109 tokens in the data.\n",
      "There are 45 unique tokens in the data.\n",
      "There are 518 characters in the data.\n",
      "The lexical diversity is 0.413 in the data.\n",
      "\n",
      "\n",
      "There are 144 tokens in the data.\n",
      "There are 84 unique tokens in the data.\n",
      "There are 705 characters in the data.\n",
      "The lexical diversity is 0.583 in the data.\n",
      "\n",
      "\n",
      "There are 67 tokens in the data.\n",
      "There are 34 unique tokens in the data.\n",
      "There are 292 characters in the data.\n",
      "The lexical diversity is 0.507 in the data.\n",
      "\n",
      "\n",
      "There are 117 tokens in the data.\n",
      "There are 52 unique tokens in the data.\n",
      "There are 627 characters in the data.\n",
      "The lexical diversity is 0.444 in the data.\n",
      "\n",
      "\n",
      "There are 117 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 636 characters in the data.\n",
      "The lexical diversity is 0.538 in the data.\n",
      "\n",
      "\n",
      "There are 103 tokens in the data.\n",
      "There are 44 unique tokens in the data.\n",
      "There are 511 characters in the data.\n",
      "The lexical diversity is 0.427 in the data.\n",
      "\n",
      "\n",
      "There are 73 tokens in the data.\n",
      "There are 61 unique tokens in the data.\n",
      "There are 387 characters in the data.\n",
      "The lexical diversity is 0.836 in the data.\n",
      "\n",
      "\n",
      "There are 87 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 400 characters in the data.\n",
      "The lexical diversity is 0.678 in the data.\n",
      "\n",
      "\n",
      "There are 84 tokens in the data.\n",
      "There are 56 unique tokens in the data.\n",
      "There are 343 characters in the data.\n",
      "The lexical diversity is 0.667 in the data.\n",
      "\n",
      "\n",
      "There are 103 tokens in the data.\n",
      "There are 36 unique tokens in the data.\n",
      "There are 444 characters in the data.\n",
      "The lexical diversity is 0.350 in the data.\n",
      "\n",
      "\n",
      "There are 110 tokens in the data.\n",
      "There are 56 unique tokens in the data.\n",
      "There are 454 characters in the data.\n",
      "The lexical diversity is 0.509 in the data.\n",
      "\n",
      "\n",
      "There are 105 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 495 characters in the data.\n",
      "The lexical diversity is 0.600 in the data.\n",
      "\n",
      "\n",
      "There are 157 tokens in the data.\n",
      "There are 68 unique tokens in the data.\n",
      "There are 684 characters in the data.\n",
      "The lexical diversity is 0.433 in the data.\n",
      "\n",
      "\n",
      "There are 168 tokens in the data.\n",
      "There are 124 unique tokens in the data.\n",
      "There are 793 characters in the data.\n",
      "The lexical diversity is 0.738 in the data.\n",
      "\n",
      "\n",
      "There are 77 tokens in the data.\n",
      "There are 68 unique tokens in the data.\n",
      "There are 391 characters in the data.\n",
      "The lexical diversity is 0.883 in the data.\n",
      "\n",
      "\n",
      "There are 120 tokens in the data.\n",
      "There are 90 unique tokens in the data.\n",
      "There are 559 characters in the data.\n",
      "The lexical diversity is 0.750 in the data.\n",
      "\n",
      "\n",
      "There are 172 tokens in the data.\n",
      "There are 66 unique tokens in the data.\n",
      "There are 882 characters in the data.\n",
      "The lexical diversity is 0.384 in the data.\n",
      "\n",
      "\n",
      "There are 115 tokens in the data.\n",
      "There are 73 unique tokens in the data.\n",
      "There are 603 characters in the data.\n",
      "The lexical diversity is 0.635 in the data.\n",
      "\n",
      "\n",
      "There are 77 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 321 characters in the data.\n",
      "The lexical diversity is 0.545 in the data.\n",
      "\n",
      "\n",
      "There are 85 tokens in the data.\n",
      "There are 37 unique tokens in the data.\n",
      "There are 380 characters in the data.\n",
      "The lexical diversity is 0.435 in the data.\n",
      "\n",
      "\n",
      "There are 76 tokens in the data.\n",
      "There are 18 unique tokens in the data.\n",
      "There are 319 characters in the data.\n",
      "The lexical diversity is 0.237 in the data.\n",
      "\n",
      "\n",
      "There are 85 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 428 characters in the data.\n",
      "The lexical diversity is 0.682 in the data.\n",
      "\n",
      "\n",
      "There are 82 tokens in the data.\n",
      "There are 28 unique tokens in the data.\n",
      "There are 369 characters in the data.\n",
      "The lexical diversity is 0.341 in the data.\n",
      "\n",
      "\n",
      "There are 115 tokens in the data.\n",
      "There are 49 unique tokens in the data.\n",
      "There are 522 characters in the data.\n",
      "The lexical diversity is 0.426 in the data.\n",
      "\n",
      "\n",
      "There are 115 tokens in the data.\n",
      "There are 67 unique tokens in the data.\n",
      "There are 497 characters in the data.\n",
      "The lexical diversity is 0.583 in the data.\n",
      "\n",
      "\n",
      "There are 112 tokens in the data.\n",
      "There are 64 unique tokens in the data.\n",
      "There are 503 characters in the data.\n",
      "The lexical diversity is 0.571 in the data.\n",
      "\n",
      "\n",
      "There are 88 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 427 characters in the data.\n",
      "The lexical diversity is 0.455 in the data.\n",
      "\n",
      "\n",
      "There are 99 tokens in the data.\n",
      "There are 66 unique tokens in the data.\n",
      "There are 443 characters in the data.\n",
      "The lexical diversity is 0.667 in the data.\n",
      "\n",
      "\n",
      "There are 127 tokens in the data.\n",
      "There are 79 unique tokens in the data.\n",
      "There are 651 characters in the data.\n",
      "The lexical diversity is 0.622 in the data.\n",
      "\n",
      "\n",
      "There are 123 tokens in the data.\n",
      "There are 83 unique tokens in the data.\n",
      "There are 554 characters in the data.\n",
      "The lexical diversity is 0.675 in the data.\n",
      "\n",
      "\n",
      "There are 112 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 495 characters in the data.\n",
      "The lexical diversity is 0.518 in the data.\n",
      "\n",
      "\n",
      "There are 114 tokens in the data.\n",
      "There are 46 unique tokens in the data.\n",
      "There are 539 characters in the data.\n",
      "The lexical diversity is 0.404 in the data.\n",
      "\n",
      "\n",
      "There are 115 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 590 characters in the data.\n",
      "The lexical diversity is 0.470 in the data.\n",
      "\n",
      "\n",
      "There are 128 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 584 characters in the data.\n",
      "The lexical diversity is 0.422 in the data.\n",
      "\n",
      "\n",
      "There are 106 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 460 characters in the data.\n",
      "The lexical diversity is 0.377 in the data.\n",
      "\n",
      "\n",
      "There are 47 tokens in the data.\n",
      "There are 25 unique tokens in the data.\n",
      "There are 201 characters in the data.\n",
      "The lexical diversity is 0.532 in the data.\n",
      "\n",
      "\n",
      "There are 91 tokens in the data.\n",
      "There are 71 unique tokens in the data.\n",
      "There are 451 characters in the data.\n",
      "The lexical diversity is 0.780 in the data.\n",
      "\n",
      "\n",
      "There are 134 tokens in the data.\n",
      "There are 71 unique tokens in the data.\n",
      "There are 652 characters in the data.\n",
      "The lexical diversity is 0.530 in the data.\n",
      "\n",
      "\n",
      "There are 114 tokens in the data.\n",
      "There are 65 unique tokens in the data.\n",
      "There are 590 characters in the data.\n",
      "The lexical diversity is 0.570 in the data.\n",
      "\n",
      "\n",
      "There are 244 tokens in the data.\n",
      "There are 87 unique tokens in the data.\n",
      "There are 1234 characters in the data.\n",
      "The lexical diversity is 0.357 in the data.\n",
      "\n",
      "\n",
      "There are 82 tokens in the data.\n",
      "There are 33 unique tokens in the data.\n",
      "There are 367 characters in the data.\n",
      "The lexical diversity is 0.402 in the data.\n",
      "\n",
      "\n",
      "There are 146 tokens in the data.\n",
      "There are 79 unique tokens in the data.\n",
      "There are 631 characters in the data.\n",
      "The lexical diversity is 0.541 in the data.\n",
      "\n",
      "\n",
      "There are 43 tokens in the data.\n",
      "There are 33 unique tokens in the data.\n",
      "There are 186 characters in the data.\n",
      "The lexical diversity is 0.767 in the data.\n",
      "\n",
      "\n",
      "There are 151 tokens in the data.\n",
      "There are 51 unique tokens in the data.\n",
      "There are 657 characters in the data.\n",
      "The lexical diversity is 0.338 in the data.\n",
      "\n",
      "\n",
      "There are 155 tokens in the data.\n",
      "There are 53 unique tokens in the data.\n",
      "There are 753 characters in the data.\n",
      "The lexical diversity is 0.342 in the data.\n",
      "\n",
      "\n",
      "There are 99 tokens in the data.\n",
      "There are 73 unique tokens in the data.\n",
      "There are 476 characters in the data.\n",
      "The lexical diversity is 0.737 in the data.\n",
      "\n",
      "\n",
      "There are 122 tokens in the data.\n",
      "There are 35 unique tokens in the data.\n",
      "There are 539 characters in the data.\n",
      "The lexical diversity is 0.287 in the data.\n",
      "\n",
      "\n",
      "There are 71 tokens in the data.\n",
      "There are 35 unique tokens in the data.\n",
      "There are 365 characters in the data.\n",
      "The lexical diversity is 0.493 in the data.\n",
      "\n",
      "\n",
      "There are 143 tokens in the data.\n",
      "There are 61 unique tokens in the data.\n",
      "There are 623 characters in the data.\n",
      "The lexical diversity is 0.427 in the data.\n",
      "\n",
      "\n",
      "There are 101 tokens in the data.\n",
      "There are 25 unique tokens in the data.\n",
      "There are 429 characters in the data.\n",
      "The lexical diversity is 0.248 in the data.\n",
      "\n",
      "\n",
      "There are 153 tokens in the data.\n",
      "There are 80 unique tokens in the data.\n",
      "There are 673 characters in the data.\n",
      "The lexical diversity is 0.523 in the data.\n",
      "\n",
      "\n",
      "There are 130 tokens in the data.\n",
      "There are 46 unique tokens in the data.\n",
      "There are 655 characters in the data.\n",
      "The lexical diversity is 0.354 in the data.\n",
      "\n",
      "\n",
      "There are 144 tokens in the data.\n",
      "There are 44 unique tokens in the data.\n",
      "There are 706 characters in the data.\n",
      "The lexical diversity is 0.306 in the data.\n",
      "\n",
      "\n",
      "There are 152 tokens in the data.\n",
      "There are 82 unique tokens in the data.\n",
      "There are 693 characters in the data.\n",
      "The lexical diversity is 0.539 in the data.\n",
      "\n",
      "\n",
      "There are 74 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 412 characters in the data.\n",
      "The lexical diversity is 0.838 in the data.\n",
      "\n",
      "\n",
      "There are 195 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 868 characters in the data.\n",
      "The lexical diversity is 0.323 in the data.\n",
      "\n",
      "\n",
      "There are 100 tokens in the data.\n",
      "There are 60 unique tokens in the data.\n",
      "There are 490 characters in the data.\n",
      "The lexical diversity is 0.600 in the data.\n",
      "\n",
      "\n",
      "There are 116 tokens in the data.\n",
      "There are 51 unique tokens in the data.\n",
      "There are 527 characters in the data.\n",
      "The lexical diversity is 0.440 in the data.\n",
      "\n",
      "\n",
      "There are 136 tokens in the data.\n",
      "There are 99 unique tokens in the data.\n",
      "There are 733 characters in the data.\n",
      "The lexical diversity is 0.728 in the data.\n",
      "\n",
      "\n",
      "There are 63 tokens in the data.\n",
      "There are 44 unique tokens in the data.\n",
      "There are 329 characters in the data.\n",
      "The lexical diversity is 0.698 in the data.\n",
      "\n",
      "\n",
      "There are 139 tokens in the data.\n",
      "There are 55 unique tokens in the data.\n",
      "There are 640 characters in the data.\n",
      "The lexical diversity is 0.396 in the data.\n",
      "\n",
      "\n",
      "There are 151 tokens in the data.\n",
      "There are 91 unique tokens in the data.\n",
      "There are 731 characters in the data.\n",
      "The lexical diversity is 0.603 in the data.\n",
      "\n",
      "\n",
      "There are 233 tokens in the data.\n",
      "There are 129 unique tokens in the data.\n",
      "There are 1110 characters in the data.\n",
      "The lexical diversity is 0.554 in the data.\n",
      "\n",
      "\n",
      "There are 105 tokens in the data.\n",
      "There are 84 unique tokens in the data.\n",
      "There are 503 characters in the data.\n",
      "The lexical diversity is 0.800 in the data.\n",
      "\n",
      "\n",
      "There are 86 tokens in the data.\n",
      "There are 39 unique tokens in the data.\n",
      "There are 429 characters in the data.\n",
      "The lexical diversity is 0.453 in the data.\n",
      "\n",
      "\n",
      "There are 100 tokens in the data.\n",
      "There are 45 unique tokens in the data.\n",
      "There are 475 characters in the data.\n",
      "The lexical diversity is 0.450 in the data.\n",
      "\n",
      "\n",
      "There are 181 tokens in the data.\n",
      "There are 115 unique tokens in the data.\n",
      "There are 953 characters in the data.\n",
      "The lexical diversity is 0.635 in the data.\n",
      "\n",
      "\n",
      "There are 97 tokens in the data.\n",
      "There are 49 unique tokens in the data.\n",
      "There are 443 characters in the data.\n",
      "The lexical diversity is 0.505 in the data.\n",
      "\n",
      "\n",
      "There are 147 tokens in the data.\n",
      "There are 53 unique tokens in the data.\n",
      "There are 647 characters in the data.\n",
      "The lexical diversity is 0.361 in the data.\n",
      "\n",
      "\n",
      "There are 71 tokens in the data.\n",
      "There are 41 unique tokens in the data.\n",
      "There are 360 characters in the data.\n",
      "The lexical diversity is 0.577 in the data.\n",
      "\n",
      "\n",
      "There are 83 tokens in the data.\n",
      "There are 55 unique tokens in the data.\n",
      "There are 421 characters in the data.\n",
      "The lexical diversity is 0.663 in the data.\n",
      "\n",
      "\n",
      "There are 109 tokens in the data.\n",
      "There are 43 unique tokens in the data.\n",
      "There are 504 characters in the data.\n",
      "The lexical diversity is 0.394 in the data.\n",
      "\n",
      "\n",
      "There are 146 tokens in the data.\n",
      "There are 91 unique tokens in the data.\n",
      "There are 731 characters in the data.\n",
      "The lexical diversity is 0.623 in the data.\n",
      "\n",
      "\n",
      "There are 159 tokens in the data.\n",
      "There are 106 unique tokens in the data.\n",
      "There are 769 characters in the data.\n",
      "The lexical diversity is 0.667 in the data.\n",
      "\n",
      "\n",
      "There are 130 tokens in the data.\n",
      "There are 77 unique tokens in the data.\n",
      "There are 640 characters in the data.\n",
      "The lexical diversity is 0.592 in the data.\n",
      "\n",
      "\n",
      "There are 121 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 606 characters in the data.\n",
      "The lexical diversity is 0.471 in the data.\n",
      "\n",
      "\n",
      "There are 99 tokens in the data.\n",
      "There are 47 unique tokens in the data.\n",
      "There are 438 characters in the data.\n",
      "The lexical diversity is 0.475 in the data.\n",
      "\n",
      "\n",
      "There are 181 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 810 characters in the data.\n",
      "The lexical diversity is 0.348 in the data.\n",
      "\n",
      "\n",
      "There are 79 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 359 characters in the data.\n",
      "The lexical diversity is 0.506 in the data.\n",
      "\n",
      "\n",
      "There are 93 tokens in the data.\n",
      "There are 46 unique tokens in the data.\n",
      "There are 379 characters in the data.\n",
      "The lexical diversity is 0.495 in the data.\n",
      "\n",
      "\n",
      "There are 210 tokens in the data.\n",
      "There are 72 unique tokens in the data.\n",
      "There are 990 characters in the data.\n",
      "The lexical diversity is 0.343 in the data.\n",
      "\n",
      "\n",
      "There are 207 tokens in the data.\n",
      "There are 78 unique tokens in the data.\n",
      "There are 872 characters in the data.\n",
      "The lexical diversity is 0.377 in the data.\n",
      "\n",
      "\n",
      "There are 54 tokens in the data.\n",
      "There are 41 unique tokens in the data.\n",
      "There are 246 characters in the data.\n",
      "The lexical diversity is 0.759 in the data.\n",
      "\n",
      "\n",
      "There are 231 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 979 characters in the data.\n",
      "The lexical diversity is 0.247 in the data.\n",
      "\n",
      "\n",
      "There are 240 tokens in the data.\n",
      "There are 70 unique tokens in the data.\n",
      "There are 1114 characters in the data.\n",
      "The lexical diversity is 0.292 in the data.\n",
      "\n",
      "\n",
      "There are 194 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 794 characters in the data.\n",
      "The lexical diversity is 0.304 in the data.\n",
      "\n",
      "\n",
      "There are 74 tokens in the data.\n",
      "There are 28 unique tokens in the data.\n",
      "There are 351 characters in the data.\n",
      "The lexical diversity is 0.378 in the data.\n",
      "\n",
      "\n",
      "There are 104 tokens in the data.\n",
      "There are 61 unique tokens in the data.\n",
      "There are 463 characters in the data.\n",
      "The lexical diversity is 0.587 in the data.\n",
      "\n",
      "\n",
      "There are 130 tokens in the data.\n",
      "There are 76 unique tokens in the data.\n",
      "There are 643 characters in the data.\n",
      "The lexical diversity is 0.585 in the data.\n",
      "\n",
      "\n",
      "There are 76 tokens in the data.\n",
      "There are 45 unique tokens in the data.\n",
      "There are 331 characters in the data.\n",
      "The lexical diversity is 0.592 in the data.\n",
      "\n",
      "\n",
      "There are 105 tokens in the data.\n",
      "There are 82 unique tokens in the data.\n",
      "There are 530 characters in the data.\n",
      "The lexical diversity is 0.781 in the data.\n",
      "\n",
      "\n",
      "There are 71 tokens in the data.\n",
      "There are 47 unique tokens in the data.\n",
      "There are 302 characters in the data.\n",
      "The lexical diversity is 0.662 in the data.\n",
      "\n",
      "\n",
      "There are 83 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 390 characters in the data.\n",
      "The lexical diversity is 0.482 in the data.\n",
      "\n",
      "\n",
      "There are 96 tokens in the data.\n",
      "There are 73 unique tokens in the data.\n",
      "There are 453 characters in the data.\n",
      "The lexical diversity is 0.760 in the data.\n",
      "\n",
      "\n",
      "There are 201 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 1018 characters in the data.\n",
      "The lexical diversity is 0.289 in the data.\n",
      "\n",
      "\n",
      "There are 89 tokens in the data.\n",
      "There are 48 unique tokens in the data.\n",
      "There are 422 characters in the data.\n",
      "The lexical diversity is 0.539 in the data.\n",
      "\n",
      "\n",
      "There are 84 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 383 characters in the data.\n",
      "The lexical diversity is 0.476 in the data.\n",
      "\n",
      "\n",
      "There are 110 tokens in the data.\n",
      "There are 52 unique tokens in the data.\n",
      "There are 451 characters in the data.\n",
      "The lexical diversity is 0.473 in the data.\n",
      "\n",
      "\n",
      "There are 85 tokens in the data.\n",
      "There are 74 unique tokens in the data.\n",
      "There are 419 characters in the data.\n",
      "The lexical diversity is 0.871 in the data.\n",
      "\n",
      "\n",
      "There are 84 tokens in the data.\n",
      "There are 66 unique tokens in the data.\n",
      "There are 433 characters in the data.\n",
      "The lexical diversity is 0.786 in the data.\n",
      "\n",
      "\n",
      "There are 229 tokens in the data.\n",
      "There are 73 unique tokens in the data.\n",
      "There are 1068 characters in the data.\n",
      "The lexical diversity is 0.319 in the data.\n",
      "\n",
      "\n",
      "There are 146 tokens in the data.\n",
      "There are 73 unique tokens in the data.\n",
      "There are 701 characters in the data.\n",
      "The lexical diversity is 0.500 in the data.\n",
      "\n",
      "\n",
      "There are 66 tokens in the data.\n",
      "There are 33 unique tokens in the data.\n",
      "There are 313 characters in the data.\n",
      "The lexical diversity is 0.500 in the data.\n",
      "\n",
      "\n",
      "There are 122 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 570 characters in the data.\n",
      "The lexical diversity is 0.516 in the data.\n",
      "\n",
      "\n",
      "There are 81 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 382 characters in the data.\n",
      "The lexical diversity is 0.667 in the data.\n",
      "\n",
      "\n",
      "There are 91 tokens in the data.\n",
      "There are 32 unique tokens in the data.\n",
      "There are 391 characters in the data.\n",
      "The lexical diversity is 0.352 in the data.\n",
      "\n",
      "\n",
      "There are 123 tokens in the data.\n",
      "There are 35 unique tokens in the data.\n",
      "There are 557 characters in the data.\n",
      "The lexical diversity is 0.285 in the data.\n",
      "\n",
      "\n",
      "There are 69 tokens in the data.\n",
      "There are 55 unique tokens in the data.\n",
      "There are 395 characters in the data.\n",
      "The lexical diversity is 0.797 in the data.\n",
      "\n",
      "\n",
      "There are 125 tokens in the data.\n",
      "There are 98 unique tokens in the data.\n",
      "There are 662 characters in the data.\n",
      "The lexical diversity is 0.784 in the data.\n",
      "\n",
      "\n",
      "There are 70 tokens in the data.\n",
      "There are 41 unique tokens in the data.\n",
      "There are 318 characters in the data.\n",
      "The lexical diversity is 0.586 in the data.\n",
      "\n",
      "\n",
      "There are 69 tokens in the data.\n",
      "There are 30 unique tokens in the data.\n",
      "There are 273 characters in the data.\n",
      "The lexical diversity is 0.435 in the data.\n",
      "\n",
      "\n",
      "There are 143 tokens in the data.\n",
      "There are 99 unique tokens in the data.\n",
      "There are 740 characters in the data.\n",
      "The lexical diversity is 0.692 in the data.\n",
      "\n",
      "\n",
      "There are 110 tokens in the data.\n",
      "There are 80 unique tokens in the data.\n",
      "There are 548 characters in the data.\n",
      "The lexical diversity is 0.727 in the data.\n",
      "\n",
      "\n",
      "There are 118 tokens in the data.\n",
      "There are 70 unique tokens in the data.\n",
      "There are 571 characters in the data.\n",
      "The lexical diversity is 0.593 in the data.\n",
      "\n",
      "\n",
      "There are 111 tokens in the data.\n",
      "There are 64 unique tokens in the data.\n",
      "There are 569 characters in the data.\n",
      "The lexical diversity is 0.577 in the data.\n",
      "\n",
      "\n",
      "There are 77 tokens in the data.\n",
      "There are 43 unique tokens in the data.\n",
      "There are 353 characters in the data.\n",
      "The lexical diversity is 0.558 in the data.\n",
      "\n",
      "\n",
      "There are 70 tokens in the data.\n",
      "There are 46 unique tokens in the data.\n",
      "There are 372 characters in the data.\n",
      "The lexical diversity is 0.657 in the data.\n",
      "\n",
      "\n",
      "There are 83 tokens in the data.\n",
      "There are 36 unique tokens in the data.\n",
      "There are 360 characters in the data.\n",
      "The lexical diversity is 0.434 in the data.\n",
      "\n",
      "\n",
      "There are 139 tokens in the data.\n",
      "There are 83 unique tokens in the data.\n",
      "There are 604 characters in the data.\n",
      "The lexical diversity is 0.597 in the data.\n",
      "\n",
      "\n",
      "There are 59 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 293 characters in the data.\n",
      "The lexical diversity is 0.915 in the data.\n",
      "\n",
      "\n",
      "There are 67 tokens in the data.\n",
      "There are 49 unique tokens in the data.\n",
      "There are 293 characters in the data.\n",
      "The lexical diversity is 0.731 in the data.\n",
      "\n",
      "\n",
      "There are 173 tokens in the data.\n",
      "There are 85 unique tokens in the data.\n",
      "There are 903 characters in the data.\n",
      "The lexical diversity is 0.491 in the data.\n",
      "\n",
      "\n",
      "There are 92 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 432 characters in the data.\n",
      "The lexical diversity is 0.435 in the data.\n",
      "\n",
      "\n",
      "There are 149 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 707 characters in the data.\n",
      "The lexical diversity is 0.416 in the data.\n",
      "\n",
      "\n",
      "There are 172 tokens in the data.\n",
      "There are 76 unique tokens in the data.\n",
      "There are 921 characters in the data.\n",
      "The lexical diversity is 0.442 in the data.\n",
      "\n",
      "\n",
      "There are 142 tokens in the data.\n",
      "There are 66 unique tokens in the data.\n",
      "There are 674 characters in the data.\n",
      "The lexical diversity is 0.465 in the data.\n",
      "\n",
      "\n",
      "There are 106 tokens in the data.\n",
      "There are 43 unique tokens in the data.\n",
      "There are 611 characters in the data.\n",
      "The lexical diversity is 0.406 in the data.\n",
      "\n",
      "\n",
      "There are 77 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 363 characters in the data.\n",
      "The lexical diversity is 0.545 in the data.\n",
      "\n",
      "\n",
      "There are 91 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 461 characters in the data.\n",
      "The lexical diversity is 0.626 in the data.\n",
      "\n",
      "\n",
      "There are 89 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 481 characters in the data.\n",
      "The lexical diversity is 0.652 in the data.\n",
      "\n",
      "\n",
      "There are 130 tokens in the data.\n",
      "There are 55 unique tokens in the data.\n",
      "There are 488 characters in the data.\n",
      "The lexical diversity is 0.423 in the data.\n",
      "\n",
      "\n",
      "There are 105 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 568 characters in the data.\n",
      "The lexical diversity is 0.590 in the data.\n",
      "\n",
      "\n",
      "There are 24 tokens in the data.\n",
      "There are 15 unique tokens in the data.\n",
      "There are 127 characters in the data.\n",
      "The lexical diversity is 0.625 in the data.\n",
      "\n",
      "\n",
      "There are 136 tokens in the data.\n",
      "There are 68 unique tokens in the data.\n",
      "There are 661 characters in the data.\n",
      "The lexical diversity is 0.500 in the data.\n",
      "\n",
      "\n",
      "There are 159 tokens in the data.\n",
      "There are 76 unique tokens in the data.\n",
      "There are 826 characters in the data.\n",
      "The lexical diversity is 0.478 in the data.\n",
      "\n",
      "\n",
      "There are 124 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 549 characters in the data.\n",
      "The lexical diversity is 0.500 in the data.\n",
      "\n",
      "\n",
      "There are 107 tokens in the data.\n",
      "There are 76 unique tokens in the data.\n",
      "There are 483 characters in the data.\n",
      "The lexical diversity is 0.710 in the data.\n",
      "\n",
      "\n",
      "There are 77 tokens in the data.\n",
      "There are 47 unique tokens in the data.\n",
      "There are 338 characters in the data.\n",
      "The lexical diversity is 0.610 in the data.\n",
      "\n",
      "\n",
      "There are 171 tokens in the data.\n",
      "There are 56 unique tokens in the data.\n",
      "There are 777 characters in the data.\n",
      "The lexical diversity is 0.327 in the data.\n",
      "\n",
      "\n",
      "There are 58 tokens in the data.\n",
      "There are 43 unique tokens in the data.\n",
      "There are 235 characters in the data.\n",
      "The lexical diversity is 0.741 in the data.\n",
      "\n",
      "\n",
      "There are 156 tokens in the data.\n",
      "There are 82 unique tokens in the data.\n",
      "There are 710 characters in the data.\n",
      "The lexical diversity is 0.526 in the data.\n",
      "\n",
      "\n",
      "There are 46 tokens in the data.\n",
      "There are 25 unique tokens in the data.\n",
      "There are 184 characters in the data.\n",
      "The lexical diversity is 0.543 in the data.\n",
      "\n",
      "\n",
      "There are 58 tokens in the data.\n",
      "There are 35 unique tokens in the data.\n",
      "There are 306 characters in the data.\n",
      "The lexical diversity is 0.603 in the data.\n",
      "\n",
      "\n",
      "There are 132 tokens in the data.\n",
      "There are 67 unique tokens in the data.\n",
      "There are 614 characters in the data.\n",
      "The lexical diversity is 0.508 in the data.\n",
      "\n",
      "\n",
      "There are 98 tokens in the data.\n",
      "There are 68 unique tokens in the data.\n",
      "There are 492 characters in the data.\n",
      "The lexical diversity is 0.694 in the data.\n",
      "\n",
      "\n",
      "There are 216 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 1097 characters in the data.\n",
      "The lexical diversity is 0.273 in the data.\n",
      "\n",
      "\n",
      "There are 111 tokens in the data.\n",
      "There are 69 unique tokens in the data.\n",
      "There are 547 characters in the data.\n",
      "The lexical diversity is 0.622 in the data.\n",
      "\n",
      "\n",
      "There are 137 tokens in the data.\n",
      "There are 80 unique tokens in the data.\n",
      "There are 592 characters in the data.\n",
      "The lexical diversity is 0.584 in the data.\n",
      "\n",
      "\n",
      "There are 84 tokens in the data.\n",
      "There are 39 unique tokens in the data.\n",
      "There are 414 characters in the data.\n",
      "The lexical diversity is 0.464 in the data.\n",
      "\n",
      "\n",
      "There are 134 tokens in the data.\n",
      "There are 61 unique tokens in the data.\n",
      "There are 582 characters in the data.\n",
      "The lexical diversity is 0.455 in the data.\n",
      "\n",
      "\n",
      "There are 58 tokens in the data.\n",
      "There are 38 unique tokens in the data.\n",
      "There are 268 characters in the data.\n",
      "The lexical diversity is 0.655 in the data.\n",
      "\n",
      "\n",
      "There are 94 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 468 characters in the data.\n",
      "The lexical diversity is 0.574 in the data.\n",
      "\n",
      "\n",
      "There are 86 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 437 characters in the data.\n",
      "The lexical diversity is 0.674 in the data.\n",
      "\n",
      "\n",
      "There are 73 tokens in the data.\n",
      "There are 35 unique tokens in the data.\n",
      "There are 328 characters in the data.\n",
      "The lexical diversity is 0.479 in the data.\n",
      "\n",
      "\n",
      "There are 81 tokens in the data.\n",
      "There are 46 unique tokens in the data.\n",
      "There are 344 characters in the data.\n",
      "The lexical diversity is 0.568 in the data.\n",
      "\n",
      "\n",
      "There are 128 tokens in the data.\n",
      "There are 35 unique tokens in the data.\n",
      "There are 551 characters in the data.\n",
      "The lexical diversity is 0.273 in the data.\n",
      "\n",
      "\n",
      "There are 169 tokens in the data.\n",
      "There are 52 unique tokens in the data.\n",
      "There are 843 characters in the data.\n",
      "The lexical diversity is 0.308 in the data.\n",
      "\n",
      "\n",
      "There are 203 tokens in the data.\n",
      "There are 80 unique tokens in the data.\n",
      "There are 881 characters in the data.\n",
      "The lexical diversity is 0.394 in the data.\n",
      "\n",
      "\n",
      "There are 68 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 296 characters in the data.\n",
      "The lexical diversity is 0.618 in the data.\n",
      "\n",
      "\n",
      "There are 118 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 567 characters in the data.\n",
      "The lexical diversity is 0.483 in the data.\n",
      "\n",
      "\n",
      "There are 75 tokens in the data.\n",
      "There are 34 unique tokens in the data.\n",
      "There are 332 characters in the data.\n",
      "The lexical diversity is 0.453 in the data.\n",
      "\n",
      "\n",
      "There are 182 tokens in the data.\n",
      "There are 34 unique tokens in the data.\n",
      "There are 704 characters in the data.\n",
      "The lexical diversity is 0.187 in the data.\n",
      "\n",
      "\n",
      "There are 130 tokens in the data.\n",
      "There are 60 unique tokens in the data.\n",
      "There are 634 characters in the data.\n",
      "The lexical diversity is 0.462 in the data.\n",
      "\n",
      "\n",
      "There are 174 tokens in the data.\n",
      "There are 83 unique tokens in the data.\n",
      "There are 853 characters in the data.\n",
      "The lexical diversity is 0.477 in the data.\n",
      "\n",
      "\n",
      "There are 165 tokens in the data.\n",
      "There are 51 unique tokens in the data.\n",
      "There are 780 characters in the data.\n",
      "The lexical diversity is 0.309 in the data.\n",
      "\n",
      "\n",
      "There are 180 tokens in the data.\n",
      "There are 76 unique tokens in the data.\n",
      "There are 849 characters in the data.\n",
      "The lexical diversity is 0.422 in the data.\n",
      "\n",
      "\n",
      "There are 8 tokens in the data.\n",
      "There are 8 unique tokens in the data.\n",
      "There are 56 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 89 tokens in the data.\n",
      "There are 53 unique tokens in the data.\n",
      "There are 428 characters in the data.\n",
      "The lexical diversity is 0.596 in the data.\n",
      "\n",
      "\n",
      "There are 65 tokens in the data.\n",
      "There are 45 unique tokens in the data.\n",
      "There are 321 characters in the data.\n",
      "The lexical diversity is 0.692 in the data.\n",
      "\n",
      "\n",
      "There are 275 tokens in the data.\n",
      "There are 132 unique tokens in the data.\n",
      "There are 1371 characters in the data.\n",
      "The lexical diversity is 0.480 in the data.\n",
      "\n",
      "\n",
      "There are 167 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 816 characters in the data.\n",
      "The lexical diversity is 0.377 in the data.\n",
      "\n",
      "\n",
      "There are 140 tokens in the data.\n",
      "There are 97 unique tokens in the data.\n",
      "There are 681 characters in the data.\n",
      "The lexical diversity is 0.693 in the data.\n",
      "\n",
      "\n",
      "There are 129 tokens in the data.\n",
      "There are 48 unique tokens in the data.\n",
      "There are 626 characters in the data.\n",
      "The lexical diversity is 0.372 in the data.\n",
      "\n",
      "\n",
      "There are 350 tokens in the data.\n",
      "There are 61 unique tokens in the data.\n",
      "There are 1532 characters in the data.\n",
      "The lexical diversity is 0.174 in the data.\n",
      "\n",
      "\n",
      "There are 149 tokens in the data.\n",
      "There are 84 unique tokens in the data.\n",
      "There are 716 characters in the data.\n",
      "The lexical diversity is 0.564 in the data.\n",
      "\n",
      "\n",
      "There are 281 tokens in the data.\n",
      "There are 89 unique tokens in the data.\n",
      "There are 1624 characters in the data.\n",
      "The lexical diversity is 0.317 in the data.\n",
      "\n",
      "\n",
      "There are 155 tokens in the data.\n",
      "There are 74 unique tokens in the data.\n",
      "There are 724 characters in the data.\n",
      "The lexical diversity is 0.477 in the data.\n",
      "\n",
      "\n",
      "There are 168 tokens in the data.\n",
      "There are 160 unique tokens in the data.\n",
      "There are 1027 characters in the data.\n",
      "The lexical diversity is 0.952 in the data.\n",
      "\n",
      "\n",
      "There are 185 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 865 characters in the data.\n",
      "The lexical diversity is 0.335 in the data.\n",
      "\n",
      "\n",
      "There are 185 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 865 characters in the data.\n",
      "The lexical diversity is 0.335 in the data.\n",
      "\n",
      "\n",
      "There are 138 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 596 characters in the data.\n",
      "The lexical diversity is 0.420 in the data.\n",
      "\n",
      "\n",
      "There are 138 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 607 characters in the data.\n",
      "The lexical diversity is 0.428 in the data.\n",
      "\n",
      "\n",
      "There are 84 tokens in the data.\n",
      "There are 30 unique tokens in the data.\n",
      "There are 375 characters in the data.\n",
      "The lexical diversity is 0.357 in the data.\n",
      "\n",
      "\n",
      "There are 174 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 1063 characters in the data.\n",
      "The lexical diversity is 0.230 in the data.\n",
      "\n",
      "\n",
      "There are 174 tokens in the data.\n",
      "There are 40 unique tokens in the data.\n",
      "There are 1063 characters in the data.\n",
      "The lexical diversity is 0.230 in the data.\n",
      "\n",
      "\n",
      "There are 149 tokens in the data.\n",
      "There are 87 unique tokens in the data.\n",
      "There are 718 characters in the data.\n",
      "The lexical diversity is 0.584 in the data.\n",
      "\n",
      "\n",
      "There are 71 tokens in the data.\n",
      "There are 36 unique tokens in the data.\n",
      "There are 285 characters in the data.\n",
      "The lexical diversity is 0.507 in the data.\n",
      "\n",
      "\n",
      "There are 95 tokens in the data.\n",
      "There are 57 unique tokens in the data.\n",
      "There are 438 characters in the data.\n",
      "The lexical diversity is 0.600 in the data.\n",
      "\n",
      "\n",
      "There are 110 tokens in the data.\n",
      "There are 70 unique tokens in the data.\n",
      "There are 499 characters in the data.\n",
      "The lexical diversity is 0.636 in the data.\n",
      "\n",
      "\n",
      "There are 102 tokens in the data.\n",
      "There are 64 unique tokens in the data.\n",
      "There are 543 characters in the data.\n",
      "The lexical diversity is 0.627 in the data.\n",
      "\n",
      "\n",
      "There are 152 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 810 characters in the data.\n",
      "The lexical diversity is 0.414 in the data.\n",
      "\n",
      "\n",
      "There are 221 tokens in the data.\n",
      "There are 61 unique tokens in the data.\n",
      "There are 989 characters in the data.\n",
      "The lexical diversity is 0.276 in the data.\n",
      "\n",
      "\n",
      "There are 93 tokens in the data.\n",
      "There are 29 unique tokens in the data.\n",
      "There are 443 characters in the data.\n",
      "The lexical diversity is 0.312 in the data.\n",
      "\n",
      "\n",
      "There are 248 tokens in the data.\n",
      "There are 113 unique tokens in the data.\n",
      "There are 1346 characters in the data.\n",
      "The lexical diversity is 0.456 in the data.\n",
      "\n",
      "\n",
      "There are 248 tokens in the data.\n",
      "There are 113 unique tokens in the data.\n",
      "There are 1346 characters in the data.\n",
      "The lexical diversity is 0.456 in the data.\n",
      "\n",
      "\n",
      "There are 224 tokens in the data.\n",
      "There are 81 unique tokens in the data.\n",
      "There are 988 characters in the data.\n",
      "The lexical diversity is 0.362 in the data.\n",
      "\n",
      "\n",
      "There are 111 tokens in the data.\n",
      "There are 70 unique tokens in the data.\n",
      "There are 520 characters in the data.\n",
      "The lexical diversity is 0.631 in the data.\n",
      "\n",
      "\n",
      "There are 214 tokens in the data.\n",
      "There are 51 unique tokens in the data.\n",
      "There are 954 characters in the data.\n",
      "The lexical diversity is 0.238 in the data.\n",
      "\n",
      "\n",
      "There are 256 tokens in the data.\n",
      "There are 96 unique tokens in the data.\n",
      "There are 1234 characters in the data.\n",
      "The lexical diversity is 0.375 in the data.\n",
      "\n",
      "\n",
      "There are 145 tokens in the data.\n",
      "There are 43 unique tokens in the data.\n",
      "There are 709 characters in the data.\n",
      "The lexical diversity is 0.297 in the data.\n",
      "\n",
      "\n",
      "There are 145 tokens in the data.\n",
      "There are 43 unique tokens in the data.\n",
      "There are 709 characters in the data.\n",
      "The lexical diversity is 0.297 in the data.\n",
      "\n",
      "\n",
      "There are 107 tokens in the data.\n",
      "There are 43 unique tokens in the data.\n",
      "There are 528 characters in the data.\n",
      "The lexical diversity is 0.402 in the data.\n",
      "\n",
      "\n",
      "There are 148 tokens in the data.\n",
      "There are 74 unique tokens in the data.\n",
      "There are 737 characters in the data.\n",
      "The lexical diversity is 0.500 in the data.\n",
      "\n",
      "\n",
      "There are 47 tokens in the data.\n",
      "There are 32 unique tokens in the data.\n",
      "There are 244 characters in the data.\n",
      "The lexical diversity is 0.681 in the data.\n",
      "\n",
      "\n",
      "There are 227 tokens in the data.\n",
      "There are 61 unique tokens in the data.\n",
      "There are 1023 characters in the data.\n",
      "The lexical diversity is 0.269 in the data.\n",
      "\n",
      "\n",
      "There are 95 tokens in the data.\n",
      "There are 65 unique tokens in the data.\n",
      "There are 455 characters in the data.\n",
      "The lexical diversity is 0.684 in the data.\n",
      "\n",
      "\n",
      "There are 112 tokens in the data.\n",
      "There are 44 unique tokens in the data.\n",
      "There are 474 characters in the data.\n",
      "The lexical diversity is 0.393 in the data.\n",
      "\n",
      "\n",
      "There are 234 tokens in the data.\n",
      "There are 89 unique tokens in the data.\n",
      "There are 1179 characters in the data.\n",
      "The lexical diversity is 0.380 in the data.\n",
      "\n",
      "\n",
      "There are 193 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 880 characters in the data.\n",
      "The lexical diversity is 0.301 in the data.\n",
      "\n",
      "\n",
      "There are 189 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 858 characters in the data.\n",
      "The lexical diversity is 0.312 in the data.\n",
      "\n",
      "\n",
      "There are 147 tokens in the data.\n",
      "There are 67 unique tokens in the data.\n",
      "There are 666 characters in the data.\n",
      "The lexical diversity is 0.456 in the data.\n",
      "\n",
      "\n",
      "There are 147 tokens in the data.\n",
      "There are 67 unique tokens in the data.\n",
      "There are 666 characters in the data.\n",
      "The lexical diversity is 0.456 in the data.\n",
      "\n",
      "\n",
      "There are 65 tokens in the data.\n",
      "There are 33 unique tokens in the data.\n",
      "There are 274 characters in the data.\n",
      "The lexical diversity is 0.508 in the data.\n",
      "\n",
      "\n",
      "There are 108 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 474 characters in the data.\n",
      "The lexical diversity is 0.500 in the data.\n",
      "\n",
      "\n",
      "There are 145 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 549 characters in the data.\n",
      "The lexical diversity is 0.428 in the data.\n",
      "\n",
      "\n",
      "There are 96 tokens in the data.\n",
      "There are 76 unique tokens in the data.\n",
      "There are 449 characters in the data.\n",
      "The lexical diversity is 0.792 in the data.\n",
      "\n",
      "\n",
      "There are 85 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 383 characters in the data.\n",
      "The lexical diversity is 0.682 in the data.\n",
      "\n",
      "\n",
      "There are 178 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 797 characters in the data.\n",
      "The lexical diversity is 0.326 in the data.\n",
      "\n",
      "\n",
      "There are 197 tokens in the data.\n",
      "There are 152 unique tokens in the data.\n",
      "There are 978 characters in the data.\n",
      "The lexical diversity is 0.772 in the data.\n",
      "\n",
      "\n",
      "There are 162 tokens in the data.\n",
      "There are 80 unique tokens in the data.\n",
      "There are 723 characters in the data.\n",
      "The lexical diversity is 0.494 in the data.\n",
      "\n",
      "\n",
      "There are 122 tokens in the data.\n",
      "There are 36 unique tokens in the data.\n",
      "There are 519 characters in the data.\n",
      "The lexical diversity is 0.295 in the data.\n",
      "\n",
      "\n",
      "There are 313 tokens in the data.\n",
      "There are 48 unique tokens in the data.\n",
      "There are 1432 characters in the data.\n",
      "The lexical diversity is 0.153 in the data.\n",
      "\n",
      "\n",
      "There are 244 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 1153 characters in the data.\n",
      "The lexical diversity is 0.172 in the data.\n",
      "\n",
      "\n",
      "There are 245 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 1158 characters in the data.\n",
      "The lexical diversity is 0.171 in the data.\n",
      "\n",
      "\n",
      "There are 146 tokens in the data.\n",
      "There are 69 unique tokens in the data.\n",
      "There are 650 characters in the data.\n",
      "The lexical diversity is 0.473 in the data.\n",
      "\n",
      "\n",
      "There are 186 tokens in the data.\n",
      "There are 75 unique tokens in the data.\n",
      "There are 995 characters in the data.\n",
      "The lexical diversity is 0.403 in the data.\n",
      "\n",
      "\n",
      "There are 96 tokens in the data.\n",
      "There are 63 unique tokens in the data.\n",
      "There are 518 characters in the data.\n",
      "The lexical diversity is 0.656 in the data.\n",
      "\n",
      "\n",
      "There are 81 tokens in the data.\n",
      "There are 30 unique tokens in the data.\n",
      "There are 342 characters in the data.\n",
      "The lexical diversity is 0.370 in the data.\n",
      "\n",
      "\n",
      "There are 76 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 310 characters in the data.\n",
      "The lexical diversity is 0.553 in the data.\n",
      "\n",
      "\n",
      "There are 99 tokens in the data.\n",
      "There are 68 unique tokens in the data.\n",
      "There are 504 characters in the data.\n",
      "The lexical diversity is 0.687 in the data.\n",
      "\n",
      "\n",
      "There are 101 tokens in the data.\n",
      "There are 68 unique tokens in the data.\n",
      "There are 519 characters in the data.\n",
      "The lexical diversity is 0.673 in the data.\n",
      "\n",
      "\n",
      "There are 124 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 548 characters in the data.\n",
      "The lexical diversity is 0.468 in the data.\n",
      "\n",
      "\n",
      "There are 124 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 548 characters in the data.\n",
      "The lexical diversity is 0.468 in the data.\n",
      "\n",
      "\n",
      "There are 94 tokens in the data.\n",
      "There are 71 unique tokens in the data.\n",
      "There are 480 characters in the data.\n",
      "The lexical diversity is 0.755 in the data.\n",
      "\n",
      "\n",
      "There are 89 tokens in the data.\n",
      "There are 62 unique tokens in the data.\n",
      "There are 413 characters in the data.\n",
      "The lexical diversity is 0.697 in the data.\n",
      "\n",
      "\n",
      "There are 95 tokens in the data.\n",
      "There are 55 unique tokens in the data.\n",
      "There are 444 characters in the data.\n",
      "The lexical diversity is 0.579 in the data.\n",
      "\n",
      "\n",
      "There are 199 tokens in the data.\n",
      "There are 74 unique tokens in the data.\n",
      "There are 948 characters in the data.\n",
      "The lexical diversity is 0.372 in the data.\n",
      "\n",
      "\n",
      "There are 51 tokens in the data.\n",
      "There are 38 unique tokens in the data.\n",
      "There are 249 characters in the data.\n",
      "The lexical diversity is 0.745 in the data.\n",
      "\n",
      "\n",
      "There are 140 tokens in the data.\n",
      "There are 96 unique tokens in the data.\n",
      "There are 696 characters in the data.\n",
      "The lexical diversity is 0.686 in the data.\n",
      "\n",
      "\n",
      "There are 51 tokens in the data.\n",
      "There are 13 unique tokens in the data.\n",
      "There are 217 characters in the data.\n",
      "The lexical diversity is 0.255 in the data.\n",
      "\n",
      "\n",
      "There are 101 tokens in the data.\n",
      "There are 36 unique tokens in the data.\n",
      "There are 463 characters in the data.\n",
      "The lexical diversity is 0.356 in the data.\n",
      "\n",
      "\n",
      "There are 136 tokens in the data.\n",
      "There are 25 unique tokens in the data.\n",
      "There are 503 characters in the data.\n",
      "The lexical diversity is 0.184 in the data.\n",
      "\n",
      "\n",
      "There are 97 tokens in the data.\n",
      "There are 67 unique tokens in the data.\n",
      "There are 475 characters in the data.\n",
      "The lexical diversity is 0.691 in the data.\n",
      "\n",
      "\n",
      "There are 97 tokens in the data.\n",
      "There are 67 unique tokens in the data.\n",
      "There are 475 characters in the data.\n",
      "The lexical diversity is 0.691 in the data.\n",
      "\n",
      "\n",
      "There are 180 tokens in the data.\n",
      "There are 58 unique tokens in the data.\n",
      "There are 807 characters in the data.\n",
      "The lexical diversity is 0.322 in the data.\n",
      "\n",
      "\n",
      "There are 83 tokens in the data.\n",
      "There are 31 unique tokens in the data.\n",
      "There are 440 characters in the data.\n",
      "The lexical diversity is 0.373 in the data.\n",
      "\n",
      "\n",
      "There are 186 tokens in the data.\n",
      "There are 90 unique tokens in the data.\n",
      "There are 820 characters in the data.\n",
      "The lexical diversity is 0.484 in the data.\n",
      "\n",
      "\n",
      "There are 72 tokens in the data.\n",
      "There are 28 unique tokens in the data.\n",
      "There are 329 characters in the data.\n",
      "The lexical diversity is 0.389 in the data.\n",
      "\n",
      "\n",
      "There are 171 tokens in the data.\n",
      "There are 97 unique tokens in the data.\n",
      "There are 771 characters in the data.\n",
      "The lexical diversity is 0.567 in the data.\n",
      "\n",
      "\n",
      "There are 127 tokens in the data.\n",
      "There are 53 unique tokens in the data.\n",
      "There are 613 characters in the data.\n",
      "The lexical diversity is 0.417 in the data.\n",
      "\n",
      "\n",
      "There are 28 tokens in the data.\n",
      "There are 15 unique tokens in the data.\n",
      "There are 110 characters in the data.\n",
      "The lexical diversity is 0.536 in the data.\n",
      "\n",
      "\n",
      "There are 106 tokens in the data.\n",
      "There are 83 unique tokens in the data.\n",
      "There are 506 characters in the data.\n",
      "The lexical diversity is 0.783 in the data.\n",
      "\n",
      "\n",
      "There are 81 tokens in the data.\n",
      "There are 59 unique tokens in the data.\n",
      "There are 421 characters in the data.\n",
      "The lexical diversity is 0.728 in the data.\n",
      "\n",
      "\n",
      "There are 322 tokens in the data.\n",
      "There are 183 unique tokens in the data.\n",
      "There are 1589 characters in the data.\n",
      "The lexical diversity is 0.568 in the data.\n",
      "\n",
      "\n",
      "There are 322 tokens in the data.\n",
      "There are 183 unique tokens in the data.\n",
      "There are 1589 characters in the data.\n",
      "The lexical diversity is 0.568 in the data.\n",
      "\n",
      "\n",
      "There are 220 tokens in the data.\n",
      "There are 72 unique tokens in the data.\n",
      "There are 1120 characters in the data.\n",
      "The lexical diversity is 0.327 in the data.\n",
      "\n",
      "\n",
      "There are 220 tokens in the data.\n",
      "There are 72 unique tokens in the data.\n",
      "There are 1120 characters in the data.\n",
      "The lexical diversity is 0.327 in the data.\n",
      "\n",
      "\n",
      "There are 53 tokens in the data.\n",
      "There are 42 unique tokens in the data.\n",
      "There are 260 characters in the data.\n",
      "The lexical diversity is 0.792 in the data.\n",
      "\n",
      "\n",
      "There are 168 tokens in the data.\n",
      "There are 54 unique tokens in the data.\n",
      "There are 754 characters in the data.\n",
      "The lexical diversity is 0.321 in the data.\n",
      "\n",
      "\n",
      "There are 104 tokens in the data.\n",
      "There are 33 unique tokens in the data.\n",
      "There are 523 characters in the data.\n",
      "The lexical diversity is 0.317 in the data.\n",
      "\n",
      "\n",
      "There are 79 tokens in the data.\n",
      "There are 56 unique tokens in the data.\n",
      "There are 349 characters in the data.\n",
      "The lexical diversity is 0.709 in the data.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song_title</th>\n",
       "      <th>song_lyrics</th>\n",
       "      <th>cleaned_lyrics</th>\n",
       "      <th>lyrics_stats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"88 Degrees\"</td>\n",
       "      <td>Stuck in L.A., ain't got no friends \\nAnd so H...</td>\n",
       "      <td>[stuck, la, aint, got, friends, hollywood, nut...</td>\n",
       "      <td>[180, 82, 0.45555555555555555, 822]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"A Different Kind Of Love Song\"</td>\n",
       "      <td>What if the world was crazy and I was sane\\nWo...</td>\n",
       "      <td>[world, crazy, sane, would, strange, cant, bel...</td>\n",
       "      <td>[133, 41, 0.3082706766917293, 670]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"After All\"</td>\n",
       "      <td>Well, here we are again\\nI guess it must be fa...</td>\n",
       "      <td>[well, guess, must, fate, weve, tried, deep, i...</td>\n",
       "      <td>[120, 59, 0.49166666666666664, 603]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"Again\"</td>\n",
       "      <td>Again evening finds me at your door \\nHere to ...</td>\n",
       "      <td>[evening, finds, door, ask, could, try, dont, ...</td>\n",
       "      <td>[34, 28, 0.8235294117647058, 143]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cher</td>\n",
       "      <td>\"Alfie\"</td>\n",
       "      <td>What's it all about, Alfie?\\nIs it just for th...</td>\n",
       "      <td>[whats, alfie, moment, live, whats, sort, alfi...</td>\n",
       "      <td>[66, 46, 0.696969696969697, 334]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                       song_title  \\\n",
       "0   cher                     \"88 Degrees\"   \n",
       "1   cher  \"A Different Kind Of Love Song\"   \n",
       "2   cher                      \"After All\"   \n",
       "3   cher                          \"Again\"   \n",
       "4   cher                          \"Alfie\"   \n",
       "\n",
       "                                         song_lyrics  \\\n",
       "0  Stuck in L.A., ain't got no friends \\nAnd so H...   \n",
       "1  What if the world was crazy and I was sane\\nWo...   \n",
       "2  Well, here we are again\\nI guess it must be fa...   \n",
       "3  Again evening finds me at your door \\nHere to ...   \n",
       "4  What's it all about, Alfie?\\nIs it just for th...   \n",
       "\n",
       "                                      cleaned_lyrics  \\\n",
       "0  [stuck, la, aint, got, friends, hollywood, nut...   \n",
       "1  [world, crazy, sane, would, strange, cant, bel...   \n",
       "2  [well, guess, must, fate, weve, tried, deep, i...   \n",
       "3  [evening, finds, door, ask, could, try, dont, ...   \n",
       "4  [whats, alfie, moment, live, whats, sort, alfi...   \n",
       "\n",
       "                          lyrics_stats  \n",
       "0  [180, 82, 0.45555555555555555, 822]  \n",
       "1   [133, 41, 0.3082706766917293, 670]  \n",
       "2  [120, 59, 0.49166666666666664, 603]  \n",
       "3    [34, 28, 0.8235294117647058, 143]  \n",
       "4     [66, 46, 0.696969696969697, 334]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply descriptive_stats to the lyrics data\n",
    "lyrics_df['lyrics_stats'] = lyrics_df['cleaned_lyrics'].apply(descriptive_stats)\n",
    "\n",
    "# Display the first few rows to check the new column\n",
    "lyrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "645be016-6d09-4c8e-9fa2-115b2b3456ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 6 tokens in the data.\n",
      "There are 6 unique tokens in the data.\n",
      "There are 33 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 3 tokens in the data.\n",
      "There are 3 unique tokens in the data.\n",
      "There are 39 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 1 tokens in the data.\n",
      "There are 1 unique tokens in the data.\n",
      "There are 3 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 17 tokens in the data.\n",
      "There are 17 unique tokens in the data.\n",
      "There are 122 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 0 tokens in the data.\n",
      "There are 0 unique tokens in the data.\n",
      "There are 0 characters in the data.\n",
      "The lexical diversity is 0.000 in the data.\n",
      "\n",
      "\n",
      "There are 5 tokens in the data.\n",
      "There are 5 unique tokens in the data.\n",
      "There are 27 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 2 tokens in the data.\n",
      "There are 2 unique tokens in the data.\n",
      "There are 10 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 0 tokens in the data.\n",
      "There are 0 unique tokens in the data.\n",
      "There are 0 characters in the data.\n",
      "The lexical diversity is 0.000 in the data.\n",
      "\n",
      "\n",
      "There are 10 tokens in the data.\n",
      "There are 9 unique tokens in the data.\n",
      "There are 52 characters in the data.\n",
      "The lexical diversity is 0.900 in the data.\n",
      "\n",
      "\n",
      "There are 3 tokens in the data.\n",
      "There are 3 unique tokens in the data.\n",
      "There are 10 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 0 tokens in the data.\n",
      "There are 0 unique tokens in the data.\n",
      "There are 0 characters in the data.\n",
      "The lexical diversity is 0.000 in the data.\n",
      "\n",
      "\n",
      "There are 5 tokens in the data.\n",
      "There are 5 unique tokens in the data.\n",
      "There are 45 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 0 tokens in the data.\n",
      "There are 0 unique tokens in the data.\n",
      "There are 0 characters in the data.\n",
      "The lexical diversity is 0.000 in the data.\n",
      "\n",
      "\n",
      "There are 0 tokens in the data.\n",
      "There are 0 unique tokens in the data.\n",
      "There are 0 characters in the data.\n",
      "The lexical diversity is 0.000 in the data.\n",
      "\n",
      "\n",
      "There are 0 tokens in the data.\n",
      "There are 0 unique tokens in the data.\n",
      "There are 0 characters in the data.\n",
      "The lexical diversity is 0.000 in the data.\n",
      "\n",
      "\n",
      "There are 0 tokens in the data.\n",
      "There are 0 unique tokens in the data.\n",
      "There are 0 characters in the data.\n",
      "The lexical diversity is 0.000 in the data.\n",
      "\n",
      "\n",
      "There are 11 tokens in the data.\n",
      "There are 11 unique tokens in the data.\n",
      "There are 72 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 0 tokens in the data.\n",
      "There are 0 unique tokens in the data.\n",
      "There are 0 characters in the data.\n",
      "The lexical diversity is 0.000 in the data.\n",
      "\n",
      "\n",
      "There are 2 tokens in the data.\n",
      "There are 2 unique tokens in the data.\n",
      "There are 12 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 0 tokens in the data.\n",
      "There are 0 unique tokens in the data.\n",
      "There are 0 characters in the data.\n",
      "The lexical diversity is 0.000 in the data.\n",
      "\n",
      "\n",
      "There are 5 tokens in the data.\n",
      "There are 5 unique tokens in the data.\n",
      "There are 20 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 4 tokens in the data.\n",
      "There are 4 unique tokens in the data.\n",
      "There are 18 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 14 tokens in the data.\n",
      "There are 14 unique tokens in the data.\n",
      "There are 76 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 4 tokens in the data.\n",
      "There are 4 unique tokens in the data.\n",
      "There are 20 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 3 tokens in the data.\n",
      "There are 3 unique tokens in the data.\n",
      "There are 12 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 6 tokens in the data.\n",
      "There are 6 unique tokens in the data.\n",
      "There are 38 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 4 tokens in the data.\n",
      "There are 4 unique tokens in the data.\n",
      "There are 21 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 2 tokens in the data.\n",
      "There are 2 unique tokens in the data.\n",
      "There are 14 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 9 tokens in the data.\n",
      "There are 9 unique tokens in the data.\n",
      "There are 37 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 11 tokens in the data.\n",
      "There are 10 unique tokens in the data.\n",
      "There are 72 characters in the data.\n",
      "The lexical diversity is 0.909 in the data.\n",
      "\n",
      "\n",
      "There are 2 tokens in the data.\n",
      "There are 2 unique tokens in the data.\n",
      "There are 4 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 21 tokens in the data.\n",
      "There are 19 unique tokens in the data.\n",
      "There are 119 characters in the data.\n",
      "The lexical diversity is 0.905 in the data.\n",
      "\n",
      "\n",
      "There are 0 tokens in the data.\n",
      "There are 0 unique tokens in the data.\n",
      "There are 0 characters in the data.\n",
      "The lexical diversity is 0.000 in the data.\n",
      "\n",
      "\n",
      "There are 14 tokens in the data.\n",
      "There are 14 unique tokens in the data.\n",
      "There are 114 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 6 tokens in the data.\n",
      "There are 6 unique tokens in the data.\n",
      "There are 23 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 0 tokens in the data.\n",
      "There are 0 unique tokens in the data.\n",
      "There are 0 characters in the data.\n",
      "The lexical diversity is 0.000 in the data.\n",
      "\n",
      "\n",
      "There are 16 tokens in the data.\n",
      "There are 16 unique tokens in the data.\n",
      "There are 105 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 11 tokens in the data.\n",
      "There are 11 unique tokens in the data.\n",
      "There are 70 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 2 tokens in the data.\n",
      "There are 2 unique tokens in the data.\n",
      "There are 11 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 13 tokens in the data.\n",
      "There are 11 unique tokens in the data.\n",
      "There are 60 characters in the data.\n",
      "The lexical diversity is 0.846 in the data.\n",
      "\n",
      "\n",
      "There are 16 tokens in the data.\n",
      "There are 16 unique tokens in the data.\n",
      "There are 104 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 0 tokens in the data.\n",
      "There are 0 unique tokens in the data.\n",
      "There are 0 characters in the data.\n",
      "The lexical diversity is 0.000 in the data.\n",
      "\n",
      "\n",
      "There are 10 tokens in the data.\n",
      "There are 10 unique tokens in the data.\n",
      "There are 51 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 0 tokens in the data.\n",
      "There are 0 unique tokens in the data.\n",
      "There are 0 characters in the data.\n",
      "The lexical diversity is 0.000 in the data.\n",
      "\n",
      "\n",
      "There are 10 tokens in the data.\n",
      "There are 10 unique tokens in the data.\n",
      "There are 68 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 13 tokens in the data.\n",
      "There are 13 unique tokens in the data.\n",
      "There are 87 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 4 tokens in the data.\n",
      "There are 4 unique tokens in the data.\n",
      "There are 21 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 3 tokens in the data.\n",
      "There are 3 unique tokens in the data.\n",
      "There are 11 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 1 tokens in the data.\n",
      "There are 1 unique tokens in the data.\n",
      "There are 6 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n",
      "\n",
      "There are 2 tokens in the data.\n",
      "There are 2 unique tokens in the data.\n",
      "There are 6 characters in the data.\n",
      "The lexical diversity is 1.000 in the data.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1                       [6, 6, 1.0, 33]\n",
       "2                       [3, 3, 1.0, 39]\n",
       "3                        [1, 1, 1.0, 3]\n",
       "4                    [17, 17, 1.0, 122]\n",
       "5                          [0, 0, 0, 0]\n",
       "6                       [5, 5, 1.0, 27]\n",
       "7                       [2, 2, 1.0, 10]\n",
       "8                          [0, 0, 0, 0]\n",
       "9                      [10, 9, 0.9, 52]\n",
       "10                      [3, 3, 1.0, 10]\n",
       "11                         [0, 0, 0, 0]\n",
       "12                      [5, 5, 1.0, 45]\n",
       "13                         [0, 0, 0, 0]\n",
       "14                         [0, 0, 0, 0]\n",
       "15                         [0, 0, 0, 0]\n",
       "16                         [0, 0, 0, 0]\n",
       "17                    [11, 11, 1.0, 72]\n",
       "18                         [0, 0, 0, 0]\n",
       "19                      [2, 2, 1.0, 12]\n",
       "20                         [0, 0, 0, 0]\n",
       "21                      [5, 5, 1.0, 20]\n",
       "22                      [4, 4, 1.0, 18]\n",
       "23                    [14, 14, 1.0, 76]\n",
       "24                      [4, 4, 1.0, 20]\n",
       "25                      [3, 3, 1.0, 12]\n",
       "26                      [6, 6, 1.0, 38]\n",
       "27                      [4, 4, 1.0, 21]\n",
       "28                      [2, 2, 1.0, 14]\n",
       "29                      [9, 9, 1.0, 37]\n",
       "30     [11, 10, 0.9090909090909091, 72]\n",
       "31                       [2, 2, 1.0, 4]\n",
       "32    [21, 19, 0.9047619047619048, 119]\n",
       "33                         [0, 0, 0, 0]\n",
       "34                   [14, 14, 1.0, 114]\n",
       "35                      [6, 6, 1.0, 23]\n",
       "36                         [0, 0, 0, 0]\n",
       "37                   [16, 16, 1.0, 105]\n",
       "38                    [11, 11, 1.0, 70]\n",
       "39                      [2, 2, 1.0, 11]\n",
       "40     [13, 11, 0.8461538461538461, 60]\n",
       "41                   [16, 16, 1.0, 104]\n",
       "42                         [0, 0, 0, 0]\n",
       "43                    [10, 10, 1.0, 51]\n",
       "44                         [0, 0, 0, 0]\n",
       "45                    [10, 10, 1.0, 68]\n",
       "46                    [13, 13, 1.0, 87]\n",
       "47                      [4, 4, 1.0, 21]\n",
       "48                      [3, 3, 1.0, 11]\n",
       "49                       [1, 1, 1.0, 6]\n",
       "50                       [2, 2, 1.0, 6]\n",
       "Name: cleaned_description, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply descriptive_stats to the Twitter data (first 50 rows)\n",
    "twitter_stats = twitter_combined.loc[1:50, 'cleaned_description'].apply(descriptive_stats)\n",
    "\n",
    "# Display the results\n",
    "twitter_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16289923-b5a8-48a0-afbd-c9b4300215e8",
   "metadata": {},
   "source": [
    "### Analyze Lexical Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94099f70-39c1-4cf4-a109-de268e03b147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Lexical Diversity Between the Artists is: \n",
      "           min     max    mean  median\n",
      "artist                                \n",
      "cher    0.2194  0.9153  0.5332  0.5273\n",
      "robyn   0.1534  1.0000  0.4742  0.4557\n"
     ]
    }
   ],
   "source": [
    "# Extract lexical diversity from the 'lyrics_stats' column\n",
    "def get_lexical_diversity(index):\n",
    "    return index[2] # 3rd element\n",
    "\n",
    "# Creates a new column 'Lexical Diversity'\n",
    "lyrics_df['lexical_diversity'] = lyrics_df['lyrics_stats'].apply(get_lexical_diversity)\n",
    "\n",
    "# Calculate min and max lexical diversity for each artist\n",
    "min_max_diversity = lyrics_df.groupby('artist')['lexical_diversity'].agg(['min', 'max', 'mean', 'median'])\n",
    "\n",
    "# Print lexical diversity range for each artist\n",
    "print('The Lexical Diversity Between the Artists is: ')\n",
    "print(min_max_diversity.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46294409",
   "metadata": {},
   "source": [
    "Q: How do you think the \"top 5 words\" would be different if we left stopwords in the data? \n",
    "\n",
    "***A: If we left stopwords in the data, the \"top 5 words\" would most likely be the more common, high-frequency words like \"the,\" \"is,\" \"and,\" \"in,\" or \"of.\" Removing stopwords allows us to focus on more informative words that better represent the content of the entry.***\n",
    "\n",
    "---\n",
    "\n",
    "Q: What were your prior beliefs about the lexical diversity between the artists? Does the difference (or lack thereof) in lexical diversity between the artists conform to your prior beliefs? \n",
    "\n",
    "***A: I expected lexical diversity to be relatively low for both Cher and Robyn because they are both pop artists who write songs targeting a mass audience. I was surprised, however, by the high lexical diversity at the upper range for both, especially seeing that Robyn achieved a max value of 1 and Cher was not far behind. I was not expecting these ranges for pop artists, who I thought wrote simple songs with repetitive lyrics. When looking at the mean and median lexical diversity values, though, they align more with my original expectations, showing that while some songs have high diversity, the overall trend is more moderate.***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4e1ac1",
   "metadata": {},
   "source": [
    "\n",
    "## Specialty Statistics\n",
    "\n",
    "The descriptive statistics we have calculated are quite generic. You will now calculate a handful of statistics tailored to these data.\n",
    "\n",
    "1. Ten most common emojis by artist in the twitter descriptions.\n",
    "1. Ten most common hashtags by artist in the twitter descriptions.\n",
    "1. Five most common words in song titles by artist. \n",
    "1. For each artist, a histogram of song lengths (in terms of number of tokens) \n",
    "\n",
    "We can use the `emoji` library to help us identify emojis and you have been given a function to help you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "753a5a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(emoji.is_emoji(\"â¤ï¸\"))\n",
    "assert(not emoji.is_emoji(\":-)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986fc4c0",
   "metadata": {},
   "source": [
    "### Emojis ğŸ˜\n",
    "\n",
    "What are the ten most common emojis by artist in the twitter descriptions? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "269cd433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cher': [('â¤', 77562),\n",
       "  ('ğŸŒˆ', 46613),\n",
       "  ('â™¥', 33422),\n",
       "  ('ğŸ³', 32759),\n",
       "  ('âœ¨', 28967),\n",
       "  ('ğŸ’™', 20974),\n",
       "  ('ğŸ»', 20532),\n",
       "  ('ğŸŒŠ', 19866),\n",
       "  ('âœŒ', 16422),\n",
       "  ('ğŸ’œ', 16256)],\n",
       " 'Robyn': [('â¤', 4663),\n",
       "  ('ğŸŒˆ', 4581),\n",
       "  ('ğŸ³', 3448),\n",
       "  ('â™¥', 3050),\n",
       "  ('âœ¨', 2177),\n",
       "  ('ğŸ»', 1473),\n",
       "  ('âœŒ', 1176),\n",
       "  ('ğŸ¼', 1113),\n",
       "  ('â™€', 819),\n",
       "  ('ğŸ’™', 788)]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract emojis from 'Cleaned Description'\n",
    "twitter_combined['Emojis'] = twitter_combined['cleaned_description'].apply(lambda x: ''.join([char for char in ' '.join(x) if char in emoji.EMOJI_DATA]))\n",
    "\n",
    "# Store emoji counts by artist\n",
    "emoji_counts_by_artist = {}\n",
    "\n",
    "# Get 10 most common emojis for each artist\n",
    "for artist in twitter_combined['artist'].unique():\n",
    "    artist_data = twitter_combined[twitter_combined['artist'] == artist]\n",
    "    all_emojis = ''.join(artist_data['Emojis'].values)\n",
    "    emoji_counts_by_artist[artist] = Counter(all_emojis).most_common(10)\n",
    "\n",
    "# Display results\n",
    "emoji_counts_by_artist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab9b770",
   "metadata": {},
   "source": [
    "### Hashtags\n",
    "\n",
    "What are the ten most common hashtags by artist in the twitter descriptions? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07c396f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cher': [('#BLM', 9350),\n",
       "  ('#Resist', 5909),\n",
       "  ('#BlackLivesMatter', 4585),\n",
       "  ('#resist', 3734),\n",
       "  ('#FBR', 3177),\n",
       "  ('#TheResistance', 2934),\n",
       "  ('#blacklivesmatter', 2591),\n",
       "  ('#1', 2585),\n",
       "  ('#Resistance', 1882),\n",
       "  ('#LGBTQ', 1785)],\n",
       " 'Robyn': [('#BlackLivesMatter', 335),\n",
       "  ('#BLM', 300),\n",
       "  ('#blacklivesmatter', 202),\n",
       "  ('#1', 197),\n",
       "  ('#music', 172),\n",
       "  ('#Music', 111),\n",
       "  ('#EDM', 85),\n",
       "  ('#LGBTQ', 74),\n",
       "  ('#TeamFollowBack', 59),\n",
       "  ('#blm', 56)]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract hashtags from 'description'\n",
    "twitter_combined['hashtags'] = twitter_combined['description'].apply(\n",
    "    lambda x: re.findall(r'#\\w+', x) if isinstance(x, str) else []\n",
    ")\n",
    "\n",
    "# Store hashtag counts by artist\n",
    "hashtag_counts_by_artist = {}\n",
    "\n",
    "# Get 10 most common hashtags for each artist\n",
    "for artist in twitter_combined['artist'].unique():\n",
    "    artist_data = twitter_combined[twitter_combined['artist'] == artist]\n",
    "    all_hashtags = [hashtag for sublist in artist_data['hashtags'].values for hashtag in sublist]\n",
    "    hashtag_counts_by_artist[artist] = Counter(all_hashtags).most_common(10)\n",
    "\n",
    "# Display results\n",
    "hashtag_counts_by_artist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10f21d5",
   "metadata": {},
   "source": [
    "### Song Titles\n",
    "\n",
    "What are the five most common words in song titles by artist? The song titles should be on the first line of the lyrics pages, so if you have kept the raw file contents around, you will not need to re-read the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb69b36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cher's Top 5 words: [('love', 38), ('man', 12), ('song', 11), ('dont', 10), ('come', 7)]\n",
      "Robyn's Top 5 words: [('love', 6), ('dont', 4), ('u', 4), ('thing', 3), ('girl', 3)]\n"
     ]
    }
   ],
   "source": [
    "# Get most common words in song titles by artist\n",
    "def most_common_title_words(df, artist, top_n=5):\n",
    "    titles = df[df['artist'] == artist]['song_title']\n",
    "    tokenized_titles = titles.apply(clean_and_tokenize)\n",
    "    all_words = [word for title in tokenized_titles for word in title]\n",
    "    return Counter(all_words).most_common(top_n)\n",
    "\n",
    "# Top 5 words for Cher and Robyn\n",
    "cher_top_5 = most_common_title_words(lyrics_df, 'cher')\n",
    "robyn_top_5 = most_common_title_words(lyrics_df, 'robyn')\n",
    "\n",
    "print(\"Cher's Top 5 words:\", cher_top_5)\n",
    "print(\"Robyn's Top 5 words:\", robyn_top_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd4fd71",
   "metadata": {},
   "source": [
    "### Song Lengths\n",
    "\n",
    "For each artist, a histogram of song lengths (in terms of number of tokens). If you put the song lengths in a data frame with an artist column, matplotlib will make the plotting quite easy. An example is given to help you out. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e562ed6-e9db-45bc-9180-ab7aa947d32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract Token Length from the 'lyrics_stats' column\n",
    "def get_token_length(index):\n",
    "    return index[0] # 1st element\n",
    "\n",
    "# Creates a new column 'Token Length'\n",
    "lyrics_df['token_length'] = lyrics_df['lyrics_stats'].apply(get_token_length)\n",
    "\n",
    "# Group by artist and plot the histogram of song lengths\n",
    "lyrics_df.groupby('artist')['token_length'].plot(kind=\"hist\", density=True, alpha=0.5, legend=True)\n",
    "plt.xlabel('Song Length (Number of Tokens)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Song Lengths by Artist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fde9ebb",
   "metadata": {},
   "source": [
    "Since the lyrics may be stored with carriage returns or tabs, it may be useful to have a function that can collapse whitespace, using regular expressions, and be used for splitting. \n",
    "\n",
    "Q: What does the regular expression `'\\s+'` match on? \n",
    "\n",
    "***A: `'\\s+'` matches on 1 or more whitespace characters (\\s is REGEX for whitespace and + is REGEX for 1 or more)***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0e34516",
   "metadata": {},
   "outputs": [],
   "source": [
    "collapse_whitespace = re.compile(r'\\s+')\n",
    "\n",
    "def tokenize_lyrics(lyric) : \n",
    "    \"\"\"strip and split on whitespace\"\"\"\n",
    "    return([item.lower() for item in collapse_whitespace.split(lyric)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2294c440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>whitespace_token_length</th>\n",
       "      <th>token_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cher</td>\n",
       "      <td>325</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cher</td>\n",
       "      <td>257</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cher</td>\n",
       "      <td>291</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cher</td>\n",
       "      <td>79</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cher</td>\n",
       "      <td>134</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>robyn</td>\n",
       "      <td>489</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>robyn</td>\n",
       "      <td>121</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>robyn</td>\n",
       "      <td>309</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>robyn</td>\n",
       "      <td>170</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>robyn</td>\n",
       "      <td>177</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    artist  whitespace_token_length  token_length\n",
       "0     cher                      325           180\n",
       "1     cher                      257           133\n",
       "2     cher                      291           120\n",
       "3     cher                       79            34\n",
       "4     cher                      134            66\n",
       "..     ...                      ...           ...\n",
       "415  robyn                      489           220\n",
       "416  robyn                      121            53\n",
       "417  robyn                      309           168\n",
       "418  robyn                      170           104\n",
       "419  robyn                      177            79\n",
       "\n",
       "[420 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your lyric length comparison chart here. \n",
    "\n",
    "# Apply tokenize_lyrics function to lyrics_df\n",
    "lyrics_df['lyrics_tokenize'] = lyrics_df['song_lyrics'].apply(tokenize_lyrics)\n",
    "\n",
    "# Apply descriptive_stats to the lyrics data and Suppress output from function\n",
    "with redirect_stdout(io.StringIO()):\n",
    "    lyrics_df['whitepsace_stats'] = lyrics_df['lyrics_tokenize'].apply(descriptive_stats)\n",
    "    \n",
    "# Creates a new column 'Whitespace Token Length' to compare lengths\n",
    "lyrics_df['whitespace_token_length'] = lyrics_df['whitepsace_stats'].apply(get_token_length)\n",
    "\n",
    "# Create comparison Data frame with desired columns\n",
    "comparison_chart_df = lyrics_df.loc[:, ['artist', 'whitespace_token_length', 'token_length']]\n",
    "\n",
    "# Display result\n",
    "comparison_chart_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54400787-cde1-401e-953b-3f0eca8ef70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Group by 'artist' and calculate mean token lengths\n",
    "grouped_df = comparison_chart_df.groupby('artist').mean()\n",
    "\n",
    "# Bar width and positions\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(grouped_df))\n",
    "\n",
    "# Create bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.bar(index, grouped_df['whitespace_token_length'], bar_width, label='Whitespace Token Length')\n",
    "ax.bar(index + bar_width, grouped_df['token_length'], bar_width, label='Token Length')\n",
    "\n",
    "# Labels, ticks, and title\n",
    "ax.set_xlabel('Artist')\n",
    "ax.set_ylabel('Token Length')\n",
    "ax.set_title('Whitespace vs. Token Length by Artist')\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels(grouped_df.index, rotation=45)\n",
    "ax.legend()\n",
    "\n",
    "# Display plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23ee3b2-b6ac-4fd2-bd59-e2b2009f8f9e",
   "metadata": {},
   "source": [
    "<center><b>References:</b></center>\n",
    "\n",
    "- Albrecht, J., Ramachandran, S., & Winkler, C. (2020). *Blueprints for text analytics using Python.* O'Reilly.\n",
    "- S, M., & Pieters, M. (2018, October 29). *How to get length of all the tokens of all the list for a given input file in python?.* Stack Overflow. https://stackoverflow.com/questions/53050095/how-to-get-length-of-all-the-tokens-of-all-the-list-for-a-given-input-file-in-py\n",
    "- McKee, A. (2024, May 23). *How to use the assert statement in Python.* DataCamp. https://www.datacamp.com/tutorial/understanding-the-python-assert-statement\n",
    "- Mayer , C. (2023, December 14). *How to Open Multiple Text Files in Python (6 Best Methods).* Be on the Right Side of Change. https://blog.finxter.com/how-to-open-multiple-text-files-in-python-6-best-methods/\n",
    "- Python Software Foundation. (n.d.). *os.path â€” Common pathname manipulations.* Python documentation. https://docs.python.org/3/library/os.path.html\n",
    "- Python Software Foundation. (n.d.). *The with statement. Python 3.11.5 documentation.* https://docs.python.org/3/reference/compound_stmts.html#the-with-statement\n",
    "- Sharma, P. (2021, June 18). *How to read multiple text files from a folder in python?(tkinter).* Tutorialspoint. https://www.tutorialspoint.com/how-to-read-multiple-text-files-from-a-folder-in-python-tkinter\n",
    "- Willems, K. (2020, January 2). *Python functions: How to call & write functions.* DataCamp. https://www.datacamp.com/tutorial/functions-python-tutorial\n",
    "- Chris, K. (2022, March 16). *Python functions â€“ how to define and call a function.* freeCodeCamp.org. https://www.freecodecamp.org/news/python-functions-define-and-call-a-function/\n",
    "- GeeksforGeeks. (2023, September 27). *Split and parse a string in Python.* https://www.geeksforgeeks.org/split-and-parse-a-string-in-python/\n",
    "- Python Software Foundation. (n.d.). *Text sequence type â€” str. Python Documentation.* https://docs.python.org/3/library/stdtypes.html#str.split\n",
    "- GeeksforGeeks. (2024, August 21). *Python: Os.path.basename() method.* https://www.geeksforgeeks.org/python-os-path-basename-method/\n",
    "- Hodgkinson, L. (2020, December 30). *NLP pipelines with NLTK.* Leeâ€™s Notebook. https://lee-hodg.github.io/blog/nlp/\n",
    "- Fuchs, M. (2021, May 25). *NLP - text pre-processing II (tokenization and stop words)* - Michael Fuchs Python. MFuchs. https://michael-fuchs-python.netlify.app/2021/05/25/nlp-text-pre-processing-ii-tokenization-and-stop-words/\n",
    "- GeeksforGeeks. (2024, January 3). *Removing stop words with NLTK in python.* GeeksforGeeks. https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "- Pandas Documentation. (n.d.). pandas.DataFrame.isna. Pandas. Retrieved September 15, 2024, from https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html\n",
    "- Singh, P. (2023, March 31). *How to remove punctuation from Python string?* - shiksha online. Study in India. https://www.shiksha.com/online-courses/articles/how-to-remove-punctuation-from-python-string/#:~:text=down%20the%20process.-,Using%20translate(),character%20or%20delete%20them%20altogether.\n",
    "- Solomon, B. (2023, July 31). *Pandas GroupBy: Your guide to grouping data in python.* Real Python. https://realpython.com/pandas-groupby/\n",
    "- Ogunbiyi, I. A. (2022, October 25). *How the Python Lambda Function Works â€“ explained with examples.* freeCodeCamp.org. https://www.freecodecamp.org/news/python-lambda-function-explained/\n",
    "- GeeksforGeeks. (2024a, August 9). *Applying lambda functions to pandas dataframe.* https://www.geeksforgeeks.org/applying-lambda-functions-to-pandas-dataframe/ \n",
    "- OpenAI. (2023). ChatGPT (September 9 version) [Large language model]. https://chat.openai.com/\n",
    "- Cloud, S. (2024, January 11). *How to remove special characters in pandas dataframe.* Saturn Cloud Blog. https://saturncloud.io/blog/how-to-remove-special-characters-in-pandas-dataframe/\n",
    "- Orozco, F. (2018, March 22). *Suppress print output in Python.* coding(dose). https://codingdose.info/posts/supress-print-output-in-python/\n",
    "- Siddharth. (2024, September 11). *How to create a bar plot in Python: A step-by-step guide (updated 2024).* Analytics Vidhya. https://www.analyticsvidhya.com/blog/2021/08/understanding-bar-plots-in-python-beginners-guide-to-data-visualization/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d660a6-ebb7-4777-80d6-b72ce535f7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
